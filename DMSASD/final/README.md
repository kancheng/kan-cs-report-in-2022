# DMSASD - 数字媒体软件与系统开发 - Digital Media Software And System Development

> 2101212850 干皓丞

PKU 2022 個人實驗報告作業

## Details

```
此為個人的論文軍火庫
```

期末工作，深度偽造、檢測、法律、時事 Deepfackes & Detection

近年來人工智能領域的蓬勃發展 ...


## Reference

1. https://zhuanlan.zhihu.com/p/90316297

2. https://zhuanlan.zhihu.com/p/92474937

3. https://zhuanlan.zhihu.com/p/92853899

4. https://zhuanlan.zhihu.com/p/115070797

5. https://github.com/HongguLiu/Deepfake-Detection

6. https://cloud.tencent.com/developer/article/1386693


## Links

1. Deep Learning for Deepfakes Creation and Detection: A Survey

https://www.researchgate.net/publication/336055871_Deep_Learning_for_Deepfakes_Creation_and_Detection_A_Survey

```
Deep learning has been successfully applied to solvevarious complex problems ranging from big data analytics tocomputer vision and human-level control. 

Deep learning advanceshowever have also been employed to create software that cancause threats to privacy, democracy and national security. 

Oneof those deep learning-powered applications recently emergedis “deepfake”. 

Deepfake algorithms can create fake images andvideos that humans cannot distinguish them from authenticones.

The proposal of technologies that can automatically detectand assess the integrity of digital visual media is thereforeindispensable.

This paper presents a survey of algorithms usedto create deepfakes and, more importantly, methods proposed todetect deepfakes in the literature to date.

We present extensivediscussions on challenges, research trends and directions relatedto deepfake technologies.

By reviewing the background of deep-fakes and state-of-the-art deepfake detection methods, this studyprovides a comprehensive overview of deepfake techniques andfacilitates the development of new and more robust methods todeal with the increasingly challenging deepfakes.
```


2. Deepfakes Detection Techniques Using Deep Learning: A Survey

https://www.scirp.org/journal/paperinformation.aspx?paperid=109149

```
Deep learning is an effective and useful technique that has been widely applied in a variety of fields, including computer vision, machine vision, and natural language processing. 

Deepfakes uses deep learning technology to manipulate images and videos of a person that humans cannot differentiate them from the real one. 

In recent years, many studies have been conducted to understand how deepfakes work and many approaches based on deep learning have been introduced to detect deepfakes videos or images. 

In this paper, we conduct a comprehensive review of deepfakes creation and detection technologies using deep learning approaches. 

In addition, we give a thorough analysis of various technologies and their application in deepfakes detection.

Our study will be beneficial for researchers in this field as it will cover the recent state-of-art methods that discover deepfakes videos or images in social contents.

In addition, it will help comparison with the existing works because of the detailed description of the latest methods and dataset used in this domain.
```

## Laws

```
法律思維與制度的智慧轉型, 李建良．劉靜怡．邱文聰．吳全峰．陳弘儒．陳柏良．何之行．廖貞．黃相博．林勤富．李怡俐．楊岳平．鄭瑞健．沈宗倫．王怡蘋
```
Link : https://www.angle.com.tw/book.asp?BKID=12196

1. 人工智慧時代的法學研究路徑初探，劉靜怡

2. 第二波人工智慧知識學習與生產對法學的挑戰 — 資訊、科技與社會研究及法學的對話，邱文聰

3. 初探人工智慧與生命倫理之關係，吳全峰

4. 初探目的解釋在法律人工智慧系統之運用可能，陳弘儒

5. AI 時代之分裂社會與民主—以美國法之表意自由與觀念市場自由競爭理論為中心，陳柏良

6. AI 個資爭議在英國與歐盟之經驗 — 以Google DeepMind一案為例，何之行、廖貞

Note : Google 醫療體系與歐盟法規之間發生的問題

7. 人工智慧在金融業的應用—論數位金融與一般個人資料保護規則之適用與衝突，黃相博

8. 人工智慧時代下的國際人權法 ─ 規範與制度的韌性探索與再建構，林勤富、李怡俐

9. 人工智慧時代下的金融監理議題 ─ 以理財機器人監理為例，楊岳平

10. 人工智慧時代下的證券監理 ─ 以智能合約在區塊鏈技術的應用出發，鄭瑞健

11. 人工智慧科技對於專利侵權法制的衝擊與因應之道 ─ 以責任歸屬為中心，沈宗倫

12. 人工智慧創作與著作權之相關問題，王怡蘋

## lists


0. Li XR, Ji SL, Wu CM, Liu ZG, Deng SG, Cheng P, Yang M, Kong XW. Survey on deepfakes and detection techniques. Ruan Jian Xue Bao/Journal of Software, 2021,32(2):496−518 (in Chinese). http://www.jos.org.cn/1000-9825/6140.htm 

Link : http://www.jos.org.cn/josen/article/abstract/6140

Note : 深度偽造與檢測綜述

```
Deep learning has achieved great success in the field of computer vision, surpassing many traditional methods. 

However, in recent years, deep learning technology has been abused in the production of fake videos, making fake videos represented by Deepfakes flooding on the Internet. 

This technique produces pornographic movies, fake news, political rumors by tampering or replacing the face information of the original videos and synthesizes fake speech. 

In order to eliminate the negative effects brought by such forgery technologies, many researchers have conducted in-depth research on the identification of fake videos and proposed a series of detection methods to help institutions or communities to identify such fake videos. 

Nevertheless, the current detection technology still has many limitations such as specific distribution data, specific compression ratio, and so on, far behind the generation technology of fake video. 

In addition, different researchers handle the problem from different angles. 

The data sets and evaluation indicators used are not uniform.

So far, the academic community still lacks a unified understanding of deep forgery and detection technology. 

The architecture of deep forgery and detection technology research is not clear.

In this review, the development of deep forgery and detection technologies are reviewed.

Besides, existing research works are systematically summarize and scientifically classified.

Finally, the social risks posed by the spread of Deepfakes technology are discussed, the limitations of detection technology are analyzed, and the challenges and potential research directions of detection technology are discussed, aiming to provide guidance for follow-up researchers to further promote the development and deployment of Deepfakes detection technology. 
```


1. Wu Z, Kinnunen T, Chng ES, Li H, Ambikairajah E. A study on spoofing attack in state-of-the-art speaker verification: The telephone speech case. In: Proc. of the Asia Pacific Signal and Information Processing Association Annual Summit and Conf. IEEE, 2012. 1−5.

Link : https://ieeexplore.ieee.org/document/6411897

Note : 深度偽造語音檢測，Wu 等人提出的歸一化的余弦相位和修改的群延遲

```
Voice conversion technique, which modifies one speaker's (source) voice to sound like another speaker (target), presents a threat to automatic speaker verification. 

In this paper, we first present new results of evaluating the vulnerability of current state-of-the-art speaker verification systems: Gaussian mixture model with joint factor analysis (GMM-JFA) and probabilistic linear discriminant analysis (PLDA) systems, against spoofing attacks. 

The spoofing attacks are simulated by two voice conversion techniques: Gaussian mixture model based conversion and unit selection based conversion. 

To reduce false acceptance rate caused by spoofing attack, we propose a general anti-spoofing attack framework for the speaker verification systems, where a converted speech detector is adopted as a post-processing module for the speaker verification system's acceptance decision. 

The detector decides whether the accepted claim is human speech or converted speech. 

A subset of the core task in the NIST SRE 2006 corpus is used to evaluate the vulnerability of speaker verification system and the performance of converted speech detector. 

The results indicate that both conversion techniques can increase the false acceptance rate of GMM-JFA and PLDA system, while the converted speech detector can reduce the false acceptance rate from 31.54% and 41.25% to 1.64% and 1.71% for GMM-JFA and PLDA system on unit-selection based converted speech, respectively.
```


2. Wu Z, Chng ES, Li H. Detecting converted speech and natural speech for anti-spoofing attack in speaker recognition. In: Proc. of the 13th Annual Conf. of the Int’l Speech Communication Association. 2012. 1700−1703.

Link : https://www.researchgate.net/publication/260343013_Detecting_Converted_Speech_and_Natural_Speech_for_anti-Spoofing_Attack_in_Speaker_Recognition

Note : 深度偽造語音檢測，Wu 等人提出的歸一化的余弦相位和修改的群延遲

```
Voice conversion techniques present a threat to speaker verification systems. 

To enhance the security of speaker verification systems, We study how to automat-ically distinguish natural speech and synthetic/converted speech. 

Motivated by the research on phase spectrum in speech perception, in this study, we propose to use fea-tures derived from phase spectrum to detect converted speech. 

The features are tested under three different train-ing situations of the converted speech detector: a) only Gaussian mixture model (GMM) based converted speech data are available; b) only unit-selection based converted speech data are available; c) no converted speech data are available for training converted speech model. 

Experi-ments conducted on the National Institute of Standards and Technology (NIST) 2006 speaker recognition evalu-ation (SRE) corpus show that the performance of the fea-tures derived from phase spectrum outperform the mel-frequency cepstral coefficients (MFCCs) tremendously: even without converted speech for training, the equal er-ror rate (EER) is reduced from 20.20% of MFCCs to 2.35%.
```

3. Das RK, Yang J, Li H. Long range acoustic and deep features perspective on ASVspoof 2019. In: Proc. of the IEEE Automatic Speech Recognition and Understanding Workshop (ASRU). IEEE, 2019. 1018−1025.

Link : https://ieeexplore.ieee.org/document/9003845

Note : 1) ASVspoof2019 資料集，2) 從遠程聲學和深度特徵的角度總結了欺騙檢測的發現且對不同類型的欺騙攻擊的性質和系統開發進行了綜合分析。

```
To secure automatic speaker verification (ASV) systems from intruders, robust countermeasures for spoofing attack detection are required.

The ASVspoof series of challenge provides a shared anti-spoofing task.

The recent edition, ASVspoof 2019, focuses on attacks by both synthetic and replay speech that are referred to as logical and physical access attacks, respectively.

In the ASVspoof 2019 submission, we considered novel countermeasures based on long range acoustic features, that are unique in many ways as they are derived using octave power spectrum and subbands, as opposed to the commonly used linear power spectrum.

During the post-challenge study, we further investigate the use of deep features that enhances the discriminative ability between genuine and spoofed speech.

In this paper, we summarize the findings from the perspective of long range acoustic and deep features for spoof detection.

We make a comprehensive analysis on the nature of different kinds of spoofing attacks and system development.
```

4. Zeinali H, Stafylakis T, Athanasopoulou G, Rohdin J, Gkinis I, Burget L, Cernocky JH. Detecting spoofing attacks using VGG and SincNet: BUT-Omilia submission to ASVspoof 2019 challenge. In: Proc. of the 20th Annual Conf. of the Int’l Speech Communication Association. 2019. 1073−1077.


Link : https://arxiv.org/abs/1907.12908

Note : 應用不同架構來應對攻擊

Tag : CVPR

```
In this paper, we present the system description of the joint efforts of Brno University of Technology (BUT) and Omilia - Conversational Intelligence for the ASVSpoof2019 Spoofing and Countermeasures Challenge.

The primary submission for Physical access (PA) is a fusion of two VGG networks, trained on single and two-channels features.

For Logical access (LA), our primary system is a fusion of VGG and the recently introduced SincNet architecture.

The results on PA show that the proposed networks yield very competitive performance in all conditions and achieved 86\:\% relative improvement compared to the official baseline.

On the other hand, the results on LA showed that although the proposed architecture and training strategy performs very well on certain spoofing attacks, it fails to generalize to certain attacks that are unseen during training.

```

5. Schörkhuber C, Klapuri A. Constant-Q transform toolbox for music processing. In: Proc. of the 7th Sound and Music Computing Conf. Barcelona, 2010. 3−64.

Link : https://core.ac.uk/download/pdf/144846462.pdf

Note : CQT 特徵，提出了一種計算時域信號恆定 Q 變換 (CQT) 的高效計算方法。

```
This paper proposes a computationally efficient method for computing the constant-Q transform (CQT) of a timedomain signal. 

CQT refers to a time-frequency representation where the frequency bins are geometrically spaced and the Q-factors (ratios of the center frequencies to bandwidths) of all bins are equal. 

An inverse transform is proposed which enables a reasonable-quality (around 55dB signal-to-noise ratio) reconstruction of the original signal from its CQT coefficients. 

Here CQTs with high Q-factors, equivalent to 12–96 bins per octave, are of particular interest.

The proposed method is flexible with regard to the number of bins per octave, the applied window function, and the Q-factor, and is particularly suitable for the analysis of music signals.

A reference implementation of the proposed methods is published as a Matlab toolbox.

The toolbox includes user-interface tools that facilitate spectral data visualization and the indexing and working with the data structure produced by the CQT.
```

6. Gomez-Alanis A, Peinado AM, Gonzalez JA, Gomez AM. A light convolutional GRU-RNN deep feature extractor for ASV spoofing detection. In: Proc. of the Interspeech 2019. 2019. 1068−1072.

Link : https://www.isca-speech.org/archive_v0/Interspeech_2019/pdfs/2212.pdf

Note : 1) 工作的目的是開發一個單一的反欺騙系統，該系統可用於有效檢測 ASVspoof 2019 挑戰賽中考慮的所有類型的欺騙攻擊。 2) 深度伪造检测算法在公开数据集上的检测表现之性能上的評估 (LightCNN+RNN \混合光卷积和门递归单元)

```
The aim of this work is to develop a single anti-spoofing system which can be applied to effectively detect all the types of spoofing attacks considered in the ASVspoof 2019 Challenge: text-to-speech, voice conversion and replay based attacks. 

To achieve this, we propose the use of a Light Convolutional Gated Recurrent Neural Network (LC-GRNN) as a deep feature extractor to robustly represent speech signals as utterance-level embeddings, which are later used by a back-end recognizer which performs the final genuine/spoofed classification. 

This novel architecture combines the ability of light convolutional layers for extracting discriminative features at frame level with the capacity of gated recurrent unit based RNNs for learning long-term dependencies of the subsequent deep features. 

The proposed system has been presented as a contribution to the ASVspoof 2019 Challenge, and the results show a significant improvement in comparison with the baseline systems. 

Moreover, experiments were also carried out on the ASVspoof 2015 and 2017 corpora, and the results indicate that our proposal clearly outperforms other popular methods recently proposed and other similar deep feature based systems.
```

7. Chen T, Kumar A, Nagarsheth P, Sivaraman G, Khoury E. Generalization of audio Deepfake detection. In: Proc. of the Odyssey 2020 Speaker and Language Recognition Workshop. 2020. 132−137.

Link : https://www.isca-speech.org/archive_v0/Odyssey_2020/pdfs/29.pdf

Note : 深度伪造检测算法在公开数据集上的检测表现之性能上的評估 (Deep Residual Network + Frequency Masking \大边际距离 & 损失函数)

```
Audio Deepfakes, technically known as logical-access voice spoofing techniques, have become an increased threat on voice interfaces due to the recent breakthroughs in speech synthesis and voice conversion technologies.

Effectively detecting these attacks is critical to many speech applications including automatic speaker verification systems.

As new types of speech synthesis and voice conversion techniques are emerging rapidly, the generalization ability of spoofing countermeasures is becoming an increasingly critical challenge.

This paper focuses on overcoming this issue by using large margin cosine loss function (LMCL) and online frequency masking augmentation to force the neural network to learn more robust feature embeddings.

We evaluate the performance of the proposed system on the ASVspoof 2019 logical access (LA) dataset.

Additionally, we evaluate it on a noisy version of the ASVspoof 2019 dataset using publicly available noises to simulate more realistic scenarios.

Finally, we evaluate the proposed system on a copy of the dataset that is logically replayed through the telephony channel to simulate spoofing attacks in the call center scenario.

Our baseline system is based on residual neural network, and has achieved the lowest equal error rate (EER) of 4.04% among all single-system submissions during the ASVspoof
2019 challenge.

Furthermore, the additional improvements proposed in this paper reduce the EER to 1.26%.
```

8. Li R, Zhao M, Li Z, Li L, Hong Q. Anti-spoofing speaker verification system with multi-feature integration and multi-task learning. In: Proc. of the Interspeech. 2019. 1048−1052.

Link : https://www.researchgate.net/publication/335829363_Anti-Spoofing_Speaker_Verification_System_with_Multi-Feature_Integration_and_Multi-Task_Learning

Note : 深度伪造检测算法在公开数据集上的检测表现之性能上的評估 (Butterfly Unit + Multi-Task \多特征融合 & 多任务学习)

```
Speaker anti-spooﬁng is crucial to prevent security breacheswhen the speaker veriﬁcation systems encounter the spoofed at-tacks from the advanced speech synthesis algorithms and highﬁdelity replay devices. 

In this paper, we propose a frameworkbased on multiple features integration and multi-task learning(MFMT) for improving anti-spooﬁng performance. 

It is im-portant to integrate the complementary information of multi-ple spectral features within the network, such as MFCC, C-QCC, Fbank, etc., as often a single kind of feature is not e-nough to grasp the global spooﬁng cues and it generalizes poor-ly. 

Furthermore, we propose a helpful butterﬂy unit (BU) formulti-task learning to propagate the shared representations be-tween the binary decision task and the other auxiliary task.

The BU can obtain task representations of other branch during for-ward propagation and prevent the gradient from assimilating thebranch during back propagation.

Our proposed system yieldedan EER of 9.01% on ASVspoof 2017, while the best single sys-tem and the average scores fusion obtained the evaluation EERof 2.39% and 0.96% on ASVspoof 2019 PA, respectively.

Index Terms: multi-feature integration, multi-task learning,stitching layer, butterﬂy unit, anti-spooﬁng, speaker veriﬁcation
```

9. Goswami G, Ratha N, Agarwal A, Singh R, Vatsa M. Unravelling robustness of deep learning based face recognition against adversarial attacks. In: Proc. of the 32nd AAAI Conf. on Artificial Intelligence. 2018. 6829−6836.


Link : https://arxiv.org/abs/1803.00401

Note : 該研究發現對人臉圖片的遮擋和加噪，能夠在一定的程度上去欺騙人臉檢測器 VGGface 和 Openface

```
Deep neural network (DNN) architecture based models have high expressive power and learning capacity. 

However, they are essentially a black box method since it is not easy to mathematically formulate the functions that are learned within its many layers of representation. 

Realizing this, many researchers have started to design methods to exploit the drawbacks of deep learning based algorithms questioning their robustness and exposing their singularities.

In this paper, we attempt to unravel three aspects related to the robustness of DNNs for face recognition: 

(i) assessing the impact of deep architectures for face recognition in terms of vulnerabilities to attacks inspired by commonly observed distortions in the real world that are well handled by shallow learning methods along with learning based adversaries; 

(ii) detecting the singularities by characterizing abnormal filter response behavior in the hidden layers of deep networks; and 

(iii) making corrections to the processing pipeline to alleviate the problem. 

Our experimental evaluation using multiple open-source DNN-based face recognition networks, including OpenFace and VGG-Face, and two publicly available databases (MEDS and PaSC) demonstrates that the performance of deep learning based face recognition algorithms can suffer greatly in the presence of such distortions. 

The proposed method is also compared with existing detection algorithms and the results show that it is able to detect the attacks with very high accuracy by suitably designing a classifier using the response of the hidden layers in the network. 

Finally, we present several effective countermeasures to mitigate the impact of adversarial attacks and improve the overall robustness of DNN-based face recognition.
```

10. Parkhi OM, Vedaldi A, Zisserman A. Deep face recognition. In: Proc. of the British Machine Vision Conf. (BMVC). BMVA Press, 2015. 41.1−41.12.

Link : https://www.robots.ox.ac.uk/~vgg/publications/2015/Parkhi15/parkhi15.pdf

Note : VGGface

```
The goal of this paper is face recognition – from either a single photograph or from a set of faces tracked in a video.

Recent progress in this area has been due to two factors:

(i) end to end learning for the task using a convolutional neural network (CNN), and 

(ii) the availability of very large scale training datasets.

We make two contributions: 

first, we show how a very large scale dataset (2.6M images, over 2.6K people) can be assembled by a combination of automation and human
in the loop, and discuss the trade off between data purity and time; 

second, we traverse through the complexities of deep network training and face recognition to present methods and procedures to achieve comparable state of the art results on the standard LFW and YTF face benchmarks.
```

11. Baltrušaitis T, Robinson P, Morency LP. Openface: An open source facial behavior analysis toolkit. In: Proc. of the IEEE Winter Conf. on Applications of Computer Vision (WACV). IEEE, 2016. 1−10.

Link : https://ieeexplore.ieee.org/document/7477553

Note : Openface

```
Over the past few years, there has been an increased interest in automatic facial behavior analysis and understanding.

We present OpenFace - an open source tool intended for computer vision and machine learning researchers, affective computing community and people interested in building interactive applications based on facial behavior analysis.

OpenFace is the first open source tool capable of facial landmark detection, head pose estimation, facial action unit recognition, and eye-gaze estimation.

The computer vision algorithms which represent the core of OpenFace demonstrate state-of-the-art results in all of the above mentioned tasks. 

Furthermore, our tool is capable of real-time performance and is able to run from a simple webcam without any specialist hardware.

Finally, OpenFace allows for easy integration with other applications and devices through a lightweight messaging system.
```

12. Li X, Ji S, Han M, Ji J, Ren Z, Liu Y, Wu C. Adversarial examples versus cloud-based detectors: A black-box empirical study. arXiv preprint arXiv:1901.01223, 2019.

Link : https://arxiv.org/abs/1901.01223

Note : 利用查询优化的方式对人脸图片进行加噪, 以此来绕过人脸识别引擎

```
Deep learning has been broadly leveraged by major cloud providers, such as Google, AWS and Baidu, to offer various computer vision related services including image classification, object identification, illegal image detection, etc. 

While recent works extensively demonstrated that deep learning classification models are vulnerable to adversarial examples, cloud-based image detection models, which are more complicated than classifiers, may also have similar security concern but not get enough attention yet.

In this paper, we mainly focus on the security issues of real-world cloud-based image detectors.

Specifically, 

(1) based on effective semantic segmentation, we propose four attacks to generate semantics-aware adversarial examples via only interacting with black-box APIs; and 

(2) we make the first attempt to conduct an extensive empirical study of black-box attacks against real-world cloud-based image detectors. 

Through the comprehensive evaluations on five major cloud platforms: 

AWS, Azure, Google Cloud, Baidu Cloud, and Alibaba Cloud, we demonstrate that our image processing based attacks can reach a success rate of approximately 100%, and the semantic segmentation based attacks have a success rate over 90% among different detection services, such as violence, politician, and pornography detection. 

We also proposed several possible defense strategies for these security challenges in the real-life situation.
```

13. Dong Y, Su H, Wu B, Li Z, Liu W, Zhang T, Zhu J. Efficient decision-based black-box adversarial attacks on face recognition. In: Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition. 2019. 7714−7722.

Link : https://arxiv.org/abs/1904.04433

Note : 利用查询优化的方式对人脸图片进行加噪, 以此来绕过人脸识别引擎

```
ace recognition has obtained remarkable progress in recent years due to the great improvement of deep convolutional neural networks (CNNs).

However, deep CNNs are vulnerable to adversarial examples, which can cause fateful consequences in real-world face recognition applications with security-sensitive purposes.

Adversarial attacks are widely studied as they can identify the vulnerability of the models before they are deployed.

In this paper, we evaluate the robustness of state-of-the-art face recognition models in the decision-based black-box attack setting, where the attackers have no access to the model parameters and gradients, but can only acquire hard-label predictions by sending queries to the target model.

This attack setting is more practical in real-world face recognition systems.

To improve the efficiency of previous methods, we propose an evolutionary attack algorithm, which can model the local geometries of the search directions and reduce the dimension of the search space.

Extensive experiments demonstrate the effectiveness of the proposed method that induces a minimum perturbation to an input face image with fewer queries.

We also apply the proposed method to attack a real-world face recognition system successfully.
```

14. Song Q, Wu Y, Yang L. Attacks on state-of-the-art face recognition using attentional adversarial attack generative network. arXiv preprint arXiv:1811.12026, 2018.

Link : https://arxiv.org/abs/1811.12026

Note : 使用注意力机制和生成对抗网络生成指定语义信息的假人脸,使得人脸识别器误判

```
With the broad use of face recognition, its weakness gradually emerges that it is able to be attacked.

So, it is important to study how face recognition networks are subject to attacks.

In this paper, we focus on a novel way to do attacks against face recognition network that misleads the network to identify someone as the target person not misclassify inconspicuously.

Simultaneously, for this purpose, we introduce a specific attentional adversarial attack generative network to generate fake face images.

For capturing the semantic information of the target person, this work adds a conditional variational autoencoder and attention modules to learn the instance-level correspondences between faces.

Unlike traditional two-player GAN, this work introduces face recognition networks as the third player to participate in the competition between generator and discriminator which allows the attacker to impersonate the target person better.

The generated faces which are hard to arouse the notice of onlookers can evade recognition by state-of-the-art networks and most of them are recognized as the target person.
```

15. Majumdar P, Agarwal A, Singh R, Vatsa M. Evading face recognition via partial tampering of faces. In: Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition Workshops. 2019. 11−20.

Link : https://ieeexplore.ieee.org/abstract/document/9025546

Note : 研究发现:对人脸部分区域的修改和变形,可以让人脸识别器有很高的误识率.

```
Advancements in machine learning and deep learning techniques have led to the development of sophisticated and accurate face recognition systems.

However, for the past few years, researchers are exploring the vulnerabilities of these systems towards digital attacks.

Creation of digitally altered images has become an easy task with the availability of various image editing tools and mobile application such as Snapchat.

Morphing based digital attacks are used to elude and gain the identity of legitimate users by fooling the deep networks.

In this research, partial face tampering attack is proposed, where facial regions are replaced or morphed to generate tampered samples.

Face verification experiments performed using two state-of-the-art face recognition systems, VGG-Face and OpenFace on the CMU-MultiPIE dataset indicates the vulnerability of these systems towards the attack.

Further, a Partial Face Tampering Detection (PFTD) network is proposed for the detection of the proposed attack.

The network captures the inconsistencies among the original and tampered images by combining the raw and high-frequency information of the input images for the detection of tampered images.

The proposed network surpasses the performance of the existing baseline deep neural networks for tampered image detection.
```

16. Korshunov P, Marcel S. Vulnerability of face recognition to deep morphing. arXiv preprint arXiv:1910.01933, 2019.

Link : https://arxiv.org/abs/1910.01933

Note : 测试了基于 VGGnet 和 FaceNet 的人脸检测器的安全性,通过输入生成的 Deepfakes 影像,发现这两类人脸检测器分别有 85.62% 和 95.00% 的错误接受率,说明人脸检测器分辨不出深度伪造人脸和
源人脸. 

```
It is increasingly easy to automatically swap faces in images and video or morph two faces into one using generative adversarial networks (GANs).

The high quality of the resulted deep-morph raises the question of how vulnerable the current face recognition systems are to such fake images and videos.

It also calls for automated ways to detect these GAN-generated faces.

In this paper, we present the publicly available dataset of the Deepfake videos with faces morphed with a GAN-based algorithm.

To generate these videos, we used open source software based on GANs, and we emphasize that training and blending parameters can significantly impact the quality of the resulted videos.

We show that the state of the art face recognition systems based on VGG and Facenet neural networks are vulnerable to the deep morph videos, with 85.62 and 95.00 false acceptance rates, respectively, which means methods for detecting these videos are necessary.

We consider several baseline approaches for detecting deep morphs and find that the method based on visual quality metrics (often used in presentation attack detection domain) leads to the best performance with 8.97 equal error rate.

Our experiments demonstrate that GAN-generated deep morph videos are challenging for both face recognition systems and existing detection methods, and the further development of deep morphing technologies will make it even more so.
```

17. Schroff F, Kalenichenko D, Philbin J. Facenet: A unified embedding for face recognition and clustering. In: Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition. 2015. 815−823.

Link : https://arxiv.org/abs/1503.03832

Note : FaceNet

```
Despite significant recent advances in the field of face recognition, implementing face verification and recognition efficiently at scale presents serious challenges to current approaches. 

In this paper we present a system, called FaceNet, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure of face similarity.

Once this space has been produced, tasks such as face recognition, verification and clustering can be easily implemented using standard techniques with FaceNet embeddings as feature vectors.

Our method uses a deep convolutional network trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches.

To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method.

The benefit of our approach is much greater representational efficiency: we achieve state-of-the-art face recognition performance using only 128-bytes per face.

On the widely used Labeled Faces in the Wild (LFW) dataset, our system achieves a new record accuracy of 99.63%. On YouTube Faces DB it achieves 95.12%.

Our system cuts the error rate in comparison to the best published result by 30% on both datasets.

We also introduce the concept of harmonic embeddings, and a harmonic triplet loss, which describe different versions of face embeddings (produced by different networks) that are compatible to each other and allow for direct comparison between each other.
```

18. Szegedy C, Zaremba W, Sutskever I, Bruna J. Intriguing properties of neural networks. In: Proc. of the 2nd Int’l Conf. on Leaning Representations (ICLR). 2014.

Link : https://arxiv.org/abs/1312.6199

Note : 神经网络本身存在着对抗样本攻击. 对抗样本攻击是一种对模型输入进行扰动,从而使模型产生误判的技术 !??

```
Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks.

While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties.

In this paper we report two such properties.

First, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis.

It suggests that it is the space, rather than the individual units, that contains of the semantic information in the high layers of neural networks.

Second, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extend.

We can cause the network to misclassify an image by applying a certain imperceptible perturbation, which is found by maximizing the network's prediction error.

In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input.
```

19. Goodfellow IJ, Shlens J, Szegedy C. Explaining and harnessing adversarial examples. In: Proc. of the 3rd Int’l Conf. on Leaning Representations (ICLR). 2015.

Link : https://arxiv.org/abs/1412.6572

Note : 神经网络本身存在着对抗样本攻击. 对抗样本攻击是一种对模型输入进行扰动,从而使模型产生误判的技术 !??

```
Several machine learning models, including neural networks, consistently misclassify adversarial examples-inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence.

Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. 

We argue instead that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature.

This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets.

Moreover, this view yields a simple and fast method of generating adversarial examples.

Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset.
```

20. Kurakin A, Goodfellow I, Bengio S. Adversarial examples in the physical world. In: Proc. of the 5th Int’l Conf. on Leaning Representations (ICLR) Workshop. 2017.

Link : https://arxiv.org/abs/1607.02533

Note : 神经网络本身存在着对抗样本攻击. 对抗样本攻击是一种对模型输入进行扰动,从而使模型产生误判的技术 !??

```
Most existing machine learning classifiers are highly vulnerable to adversarial examples.

An adversarial example is a sample of input data which has been modified very slightly in a way that is intended to cause a machine learning classifier to misclassify it. 

In many cases, these modifications can be so subtle that a human observer does not even notice the modification at all, yet the classifier still makes a mistake.

Adversarial examples pose security concerns because they could be used to perform an attack on machine learning systems, even if the adversary has no access to the underlying model.

Up to now, all previous work have assumed a threat model in which the adversary can feed data directly into the machine learning classifier.

This is not always the case for systems operating in the physical world, for example those which are using signals from cameras and other sensors as an input.

This paper shows that even in such physical world scenarios, machine learning systems are vulnerable to adversarial examples.

We demonstrate this by feeding adversarial images obtained from cell-phone camera to an ImageNet Inception classifier and measuring the classification accuracy of the system.

We find that a large fraction of adversarial examples are classified incorrectly even when perceived through the camera.
```

21. Wang SY, Wang O, Zhang R, Owens A, Efros AA. CNN-generated images are surprisingly easy to spot for now. In: Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). 2020. 8692−8701.

Link : https://arxiv.org/abs/1912.11035

Note : 研究发现不同的 GAN 生成的伪造图像都留下特定的指纹特征,虽然依赖于指纹特征训练的检测器泛化能力不好,但是对训练数据进行预处理,如增加 JPEG 压缩、模糊等操作,大大提高模型的泛化性能,同时在检测时对图片进行后处理,可以增加模型的鲁棒性

```
In this work we ask whether it is possible to create a "universal" detector for telling apart real images from these generated by a CNN, regardless of architecture or dataset used.

To test this, we collect a dataset consisting of fake images generated by 11 different CNN-based image generator models, chosen to span the space of commonly used architectures today (ProGAN, StyleGAN, BigGAN, CycleGAN, StarGAN, GauGAN, DeepFakes, cascaded refinement networks, implicit maximum likelihood estimation, second-order attention super-resolution, seeing-in-the-dark).

We demonstrate that, with careful pre- and post-processing and data augmentation, a standard image classifier trained on only one specific CNN generator (ProGAN) is able to generalize surprisingly well to unseen architectures, datasets, and training methods (including the just released StyleGAN2).

Our findings suggest the intriguing possibility that today's CNN-generated images share some common systematic flaws, preventing them from achieving realistic image synthesis.

Code and pre-trained networks are available at this https URL .

https://peterwang512.github.io/CNNDetection/
```

22. Neves JC, Tolosana R, Vera-Rodriguez R, Vera-Rodriguez R, Lopes V, Proena H, Fierrez J. Ganprintr: Improved fakes and evaluation of the state-of-the-art in face manipulation detection. IEEE Journal of Selected Topics in Signal Processing, 2020,14(5): 1038−1048.

Link : https://arxiv.org/abs/1911.05351

Note : 设计了一个自动编码器能够将合成的伪造图像移除指纹等信息,让现有的伪造检测系统失效

```
The availability of large-scale facial databases, together with the remarkable progresses of deep learning technologies, in particular Generative Adversarial Networks (GANs), have led to the generation of extremely realistic fake facial content, raising obvious concerns about the potential for misuse. 

Such concerns have fostered the research on manipulation detection methods that, contrary to humans, have already achieved astonishing results in various scenarios.

In this study, we focus on the synthesis of entire facial images, which is a specific type of facial manipulation.

The main contributions of this study are four-fold: 

i) a novel strategy to remove GAN "fingerprints" from synthetic fake images based on autoencoders is described, in order to spoof facial manipulation detection systems while keeping the visual quality of the resulting images;

ii) an in-depth analysis of the recent literature in facial manipulation detection;

iii) a complete experimental assessment of this type of facial manipulation, considering the state-of-the-art fake detection systems (based on holistic deep networks, steganalysis, and local artifacts), remarking how challenging is this task in unconstrained scenarios; and finally

iv) we announce a novel public database, named iFakeFaceDB, yielding from the application of our proposed GAN-fingerprint Removal approach (GANprintR) to already very realistic synthetic fake images.

The results obtained in our empirical evaluation show that additional efforts are required to develop robust facial manipulation detection systems against unseen conditions and spoof techniques, such as the one proposed in this study.
```

23. Marra F, Gragnaniello D, Cozzolino D, Verdoliva L. Detection of GAN-generated fake images over social networks. In: Proc. of the IEEE Conf. on Multimedia Information Processing and Retrieval (MIPR). IEEE, 2018. 384−389.

Link : https://ieeexplore.ieee.org/document/8397040

Note : 模拟了篡改图片在社交网络的场景中的检测,结果显示,现有的检测器在现实网络对抗环境下(未知压缩和未知类型等)表现很差

```
The diffusion of fake images and videos on social networks is a fast growing problem.

Commercial media editing tools allow anyone to remove, add, or clone people and objects, to generate fake images.

Many techniques have been proposed to detect such conventional fakes, but new attacks emerge by the day.

Image-to-image translation, based on generative adversarial networks (GANs), appears as one of the most dangerous, as it allows one to modify context and semantics of images in a very realistic way.

In this paper, we study the performance of several image forgery detectors against image-to-image translation, both in ideal conditions, and in the presence of compression, routinely performed upon uploading on social networks.

The study, carried out on a dataset of 36302 images, shows that detection accuracies up to 95% can be achieved by both conventional and deep learning detectors, but only the latter keep providing a high accuracy, up to 89%, on compressed data.
```

24. Zhang X, Karaman S, Chang SF. Detecting and simulating artifacts in GAN fake images. In: Proc. of the IEEE Int’l Workshop on Information Forensics and Security (WIFS). 2019. 1−6.

Link : https://arxiv.org/pdf/1907.06515.pdf

Note : 寻找 GAN 的共有痕迹,提高检测器的鲁棒性.现有的检测器对数据依赖强,泛化性不够

```
To detect GAN generated images, conventional supervised machine learning algorithms require collection of a number of real and fake images from the targeted GAN model.

However, the specific model used by the attacker is often unavailable.

To address this, we propose a GAN simulator, AutoGAN, which can simulate the artifacts produced by the common pipeline shared by several popular GAN models.

Additionally, we identify a unique artifact caused by the up-sampling component included in the common GAN pipeline.

We show theoretically such artifacts are manifested as replications of spectra in the frequency domain and thus propose a classifier model based on the spectrum input, rather than the pixel input.

By using the simulated images to train a spectrum based classifier, even without seeing the fake images produced by the targeted GAN model during training, our approach achieves state-of-the-art performances on detecting fake images generated by popular GAN models such as CycleGAN.
```

25. Du M, Pentyala S, Li Y, Hu X. Towards generalizable forgery detection with locality-aware autoencoder. arXiv preprint arXiv: 1909.05999, 2019.

Link : https://arxiv.org/abs/1909.05999

Note : 利用局部性感知的自动编码器实现造检测,使得模型聚焦篡改区域,通用性更强

```
With advancements of deep learning techniques, it is now possible to generate super-realistic images and videos, i.e., deepfakes.

These deepfakes could reach mass audience and result in adverse impacts on our society.

Although lots of efforts have been devoted to detect deepfakes, their performance drops significantly on previously unseen but related manipulations and the detection generalization capability remains a problem.

Motivated by the fine-grained nature and spatial locality characteristics of deepfakes, we propose Locality-Aware AutoEncoder (LAE) to bridge the generalization gap.

In the training process, we use a pixel-wise mask to regularize local interpretation of LAE to enforce the model to learn intrinsic representation from the forgery region, instead of capturing artifacts in the training set and learning superficial correlations to perform detection.

We further propose an active learning framework to select the challenging candidates for labeling, which requires human masks for less than 3% of the training data, dramatically reducing the annotation efforts to regularize interpretations.

Experimental results on three deepfake detection tasks indicate that LAE could focus on the forgery regions to make decisions.

The analysis further shows that LAE outperforms the state-of-the-arts by 6.52%, 12.03%, and 3.08% respectively on three deepfake detection tasks in terms of generalization accuracy on previously unseen manipulations.
```

26. Huang R, Fang F, Nguyen HH, Yamagishi J, Echizen I. Security of facial forensics models against adversarial attacks. arXiv preprint arXiv:1911.00660, 2019.

Link : https://arxiv.org/abs/1911.00660

Note : 借鉴了对抗样本的思想,对这些基于神经网络的检测器进行对抗性攻击,设计了单个对抗攻击和通用对抗攻击两种方式,使得检测器的篡改分类和定位失效.尽管现在已经存在众多的检测器,在一些数据集上表现很好,但是攻击者依然可以完善生成方法,隐藏一些标志性特征从而绕过检测器,这是一个长期的攻防博弈过程. 

```
Deep neural networks (DNNs) have been used in digital forensics to identify fake facial images.

We investigated several DNN-based forgery forensics models (FFMs) to examine whether they are secure against adversarial attacks.

We experimentally demonstrated the existence of individual adversarial perturbations (IAPs) and universal adversarial perturbations (UAPs) that can lead a well-performed FFM to misbehave.

Based on iterative procedure, gradient information is used to generate two kinds of IAPs that can be used to fabricate classification and segmentation outputs.

In contrast, UAPs are generated on the basis of over-firing.

We designed a new objective function that encourages neurons to over-fire, which makes UAP generation feasible even without using training data.

Experiments demonstrated the transferability of UAPs across unseen datasets and unseen FFMs.

Moreover, we conducted subjective assessment for imperceptibility of the adversarial perturbations, revealing that the crafted UAPs are visually negligible.

These findings provide a baseline for evaluating the adversarial security of FFMs.
```
27. Hall HK. Deepfake videos: When seeing isn’t believing. Catholic University Journal of Law and Technology, 2018,27(1):Article No.51.

Link : https://scholarship.law.edu/jlt/vol27/iss1/4/#:~:text=Videos%2C%20known%20as%20deepfakes%2C%20use,videos%20are%20fact%20or%20fiction.

Note : 深度伪造技术的发展给社会带来了巨大的负面影响,从社会国家领导人到普通的互联网公民,都有被此类技术侵害的可能性

```
Videos, known as deepfakes, use readily available software to create a work that shows people saying and doing things they may never have uttered or engaged in.

The technology making the videos appear very authentic is advancing at such a rate that people may not be able to detect if the videos are fact or fiction.

Given the hasty acceptance of other forms of fake news in society, deepfake videos have the ability to affect the nature of information the public receives about candidates and policies.

This study examines the potential use of deepfake videos in the democratic process, analyzes the challenges in regulating this area due to the First Amendment, questions the practicality of the marketplace of ideas metaphor in today’s news and information environment, and explores possible responses to the spread of deepfakes.
```

28. Hasan HR, Salah K. Combating deepfake videos using blockchain and smart contracts. IEEE Access, 2019,7:41596−41606.

Link : https://ieeexplore.ieee.org/document/8668407

Note : 尝试用区块链技术对互联网上的视频进行追踪

```
With the rise of artificial intelligence (AI) and deep learning techniques, fake digital contents have proliferated in recent years.

Fake footage, images, audios, and videos (known as deepfakes) can be a scary and dangerous phenomenon and can have the potential of altering the truth and eroding trust by giving false reality.

Proof of authenticity (PoA) of digital media is critical to help eradicate the epidemic of forged content.

Current solutions lack the ability to provide history tracking and provenance of digital media.

In this paper, we provide a solution and a general framework using Ethereum smart contracts to trace and track the provenance and history of digital content to its original source even if the digital content is copied multiple times.

The smart contract utilizes the hashes of the interplanetary file system (IPFS) used to store digital content and its metadata.

Our solution focuses on video content, but the solution framework provided in this paper is generic enough and can be applied to any other form of digital content.

Our solution relies on the principle that if the content can be credibly traced to a trusted or reputable source, the content can then be real and authentic.

The full code of the smart contract has been made publicly available at Github.
```

29. The law of California to Deepfake. 2019. https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201920200AB730

Link : https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201920200AB730

Note : 加州修法

```
AB 730, Berman. Elections: deceptive audio or visual media.

Existing law prohibits a person or specified entity from, with actual malice, producing, distributing, publishing, or broadcasting campaign material, as defined, that contains (1) a picture or photograph of a person or persons into which the image of a candidate for public office is superimposed or (2) a picture or photograph of a candidate for public office into which the image of another person or persons is superimposed, unless the campaign material contains a specified disclosure.
```

30. Regulations of China Internet Information Office on the control of online content. 2020 (in Chinese). http://www.cac.gov.cn/2019-12/20/c_1578375159509309.htm

Link : http://www.cac.gov.cn/2019-12/20/c_1578375159509309.htm

Note : 网络信息内容生态治理规定

```
国家互联网信息办公室令

第5号

　　《网络信息内容生态治理规定》已经国家互联网信息办公室室务会议审议通过，现予公布，自2020年3月1日起施行。 
...
```

31. Nataraj L, Mohammed TM, Chandrasekaran S, Flenner A, Bappy JH, Roy-Chowdhury AK, Manjunath BS. Detecting GAN generated fake images using co-occurrence matrices. Electronic Imaging, 2019,2019(5):532-1−532-7.

Link : https://arxiv.org/abs/1903.06836

Note : : GAN 生成技术改变了图像的像素和色度空间统计特征,通过对特征共生矩阵的学习来区分生成图像的差异

```
The advent of Generative Adversarial Networks (GANs) has brought about completely novel ways of transforming and manipulating pixels in digital images. 

GAN based techniques such as Image-to-Image translations, DeepFakes, and other automated methods have become increasingly popular in creating fake images. 

In this paper, we propose a novel approach to detect GAN generated fake images using a combination of co-occurrence matrices and deep learning. 

We extract co-occurrence matrices on three color channels in the pixel domain and train a model using a deep convolutional neural network (CNN) framework. 

Experimental results on two diverse and challenging GAN datasets comprising more than 56,000 images based on unpaired image-to-image translations (cycleGAN [1]) and facial attributes/expressions (StarGAN [2]) show that our approach is promising and achieves more than 99% classification accuracy in both datasets. 

Further, our approach also generalizes well and achieves good results when trained on one dataset and tested on the other.
```

32. Li H, Li B, Tan S, Huang J. Identification of deep network generated images using disparities in color components. arXiv preprint arXiv:1808.07276, 2018.

Link : https://arxiv.org/abs/1808.07276

Note : GAN 生成技术改变了图像的像素和色度空间统计特征,通过对特征共生矩阵的学习来区分生成图像的差异

```
With the powerful deep network architectures, such as generative adversarial networks, one can easily generate photorealistic images. 

Although the generated images are not dedicated for fooling human or deceiving biometric authentication systems, research communities and public media have shown great concerns on the security issues caused by these images. 

This paper addresses the problem of identifying deep network generated (DNG) images. 

Taking the differences between camera imaging and DNG image generation into considerations, we analyze the disparities between DNG images and real images in different color components. 

We observe that the DNG images are more distinguishable from real ones in the chrominance components, especially in the residual domain. 

Based on these observations, we propose a feature set to capture color image statistics for identifying DNG images. 

Additionally, we evaluate several detection situations, including the training-testing data are matched or mismatched in image sources or generative models and detection with only real images. 

Extensive experimental results show that the proposed method can accurately identify DNG images and outperforms existing methods when the training and testing data are mismatched. 

Moreover, when the GAN model is unknown, our methods also achieves good performance with one-class classification by using only real images for training.
```

33. Xuan X, Peng B, Wang W, Dong J. On the generalization of GAN image forensics. In: Proc. of the Chinese Conf. on Biometric Recognition. Cham: Springer-Verlag, 2019. 134−141.

Link : https://paperswithcode.com/paper/on-the-generalization-of-gan-image-forensics

Note : Xuan 等人使用图像预处理,如滤波、噪音等预处理方法破坏 GAN 图像低级别的生成缺陷,迫使模型学习高级别的固有的线索.S

```
Recently the GAN generated face images are more and more realistic with high-quality, even hard for human eyes to detect. 

On the other hand, the forensics community keeps on developing methods to detect these generated fake images and try to guarantee the credibility of visual contents.

Although researchers have developed some methods to detect generated images, few of them explore the important problem of generalization ability of forensics model.

As new types of GANs are emerging fast, the generalization ability of forensics models to detect new types of GAN images is absolutely an essential research topic.

In this paper, we explore this problem and propose to use preprocessed images to train a forensic CNN model. 

By applying similar image level preprocessing to both real and fake training images, the forensics model is forced to learn more intrinsic features to classify the generated and real face images.

Our experimental results also prove the effectiveness of the proposed method.
```

34. McCloskey S, Albright M. Detecting GAN-generated imagery using color cues. arXiv preprint arXiv:1812.08247, 2018.

Link : https://arxiv.org/abs/1812.08247

Note : 发现:GAN 生成器的中间值通常通过归一化来限制输出,这一定程度上也会限制饱和像素的频率.

```
Image forensics is an increasingly relevant problem, as it can potentially address online disinformation campaigns and mitigate problematic aspects of social media. 

Of particular interest, given its recent successes, is the detection of imagery produced by Generative Adversarial Networks (GANs), e.g. `deepfakes'. 

Leveraging large training sets and extensive computing resources, recent work has shown that GANs can be trained to generate synthetic imagery which is (in some ways) indistinguishable from real imagery. 

We analyze the structure of the generating network of a popular GAN implementation, and show that the network's treatment of color is markedly different from a real camera in two ways. 

We further show that these two cues can be used to distinguish GAN-generated imagery from camera imagery, demonstrating effective discrimination between GAN imagery and real camera images used to train the GAN.
```

35. Marra F, Gragnaniello D, Verdoliva L, Poggi G. Do GANs leave artificial fingerprints? In: Proc. of the IEEE Conf. on Multimedia Information Processing and Retrieval (MIPR). IEEE, 2019. 506−511.

Link : https://arxiv.org/abs/1812.11842

Note : 指纹来区分伪造,不同的 GAN 生成的图片在中间分类层具有唯一的特征,可以作为 GAN 生成器的辨别指纹.

```
In the last few years, generative adversarial networks (GAN) have shown tremendous potential for a number of applications in computer vision and related fields. 

With the current pace of progress, it is a sure bet they will soon be able to generate high-quality images and videos, virtually indistinguishable from real ones. 

Unfortunately, realistic GAN-generated images pose serious threats to security, to begin with a possible flood of fake multimedia, and multimedia forensic countermeasures are in urgent need. 

In this work, we show that each GAN leaves its specific fingerprint in the images it generates, just like real-world cameras mark acquired images with traces of their photo-response non-uniformity pattern. 

Source identification experiments with several popular GANs show such fingerprints to represent a precious asset for forensic analyses.
```

36. Yu N, Davis LS, Fritz M. Attributing fake images to GANs: Learning and analyzing GAN fingerprints. In: Proc. of the IEEE Int’l Conf. on Computer Vision. 2019. 7556−7566.

Link : https://arxiv.org/abs/1811.08180

Note : 指纹来区分伪造,不同的 GAN 生成的图片在中间分类层具有唯一的特征,可以作为 GAN 生成器的辨别指纹.

```
Recent advances in Generative Adversarial Networks (GANs) have shown increasing success in generating photorealistic images. 

But they also raise challenges to visual forensics and model attribution. 

We present the first study of learning GAN fingerprints towards image attribution and using them to classify an image as real or GAN-generated. 

For GAN-generated images, we further identify their sources. 

Our experiments show that (1) GANs carry distinct model fingerprints and leave stable fingerprints in their generated images, which support image attribution; 

(2) even minor differences in GAN training can result in different fingerprints, which enables fine-grained model authentication; 

(3) fingerprints persist across different image frequencies and patches and are not biased by GAN artifacts; 

(4) fingerprint finetuning is effective in immunizing against five types of adversarial image perturbations;

 and (5) comparisons also show our learned fingerprints consistently outperform several baselines in a variety of setups.
```

37. Wang R, Ma L, Juefei-Xu F, Xie X, Wang J, Liu Y. Fakespotter: A simple baseline for spotting ai-synthesized fake faces. In: Proc. of the 29th Int’l Joint Conf. on Artifical Intelligence (IJCAI). 2020. 3444−3451.

Link : https://arxiv.org/abs/1909.06122

Note : 提出了 FakeSpotter,利用神经元监控的方法来进行分类.使用神经元覆盖的方法观察真假图像经过人脸识别器中的神经元激活变化情况,用 SVM 去学习神经元激活的差异,而假脸在神经
元覆盖的行为上表示相似.

```
In recent years, generative adversarial networks (GANs) and its variants have achieved unprecedented success in image synthesis. 

They are widely adopted in synthesizing facial images which brings potential security concerns to humans as the fakes spread and fuel the misinformation. 

However, robust detectors of these AI-synthesized fake faces are still in their infancy and are not ready to fully tackle this emerging challenge. 

In this work, we propose a novel approach, named FakeSpotter, based on monitoring neuron behaviors to spot AI-synthesized fake faces. 

The studies on neuron coverage and interactions have successfully shown that they can be served as testing criteria for deep learning systems, especially under the settings of being exposed to adversarial attacks. 

Here, we conjecture that monitoring neuron behavior can also serve as an asset in detecting fake faces since layer-by-layer neuron activation patterns may capture more subtle features that are important for the fake detector. 

Experimental results on detecting four types of fake faces synthesized with the state-of-the-art GANs and evading four perturbation attacks show the effectiveness and robustness of our approach.
```

38. Chollet F. Xception: Deep learning with depthwise separable convolutions. In: Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition. 2017. 1251−1258.

Link : https://arxiv.org/abs/1610.02357

Note : 利用 Xception 架构对视频的全帧和人脸分别训练.结果显示,基于人脸训练的模型效果远远好于全帧模型.同时,实验结果显示:在面对高度压缩的图片时,模型的训练难度会上升且检测率会下降

```
We present an interpretation of Inception modules in convolutional neural networks as being an intermediate step in-between regular convolution and the depthwise separable convolution operation (a depthwise convolution followed by a pointwise convolution).

In this light, a depthwise separable convolution can be understood as an Inception module with a maximally large number of towers. 

This observation leads us to propose a novel deep convolutional neural network architecture inspired by Inception, where Inception modules have been replaced with depthwise separable convolutions. 

We show that this architecture, dubbed Xception, slightly outperforms Inception V3 on the ImageNet dataset (which Inception V3 was designed for), and significantly outperforms Inception V3 on a larger image classification dataset comprising 350 million images and 17,000 classes. 

Since the Xception architecture has the same number of parameters as Inception V3, the performance gains are not due to increased capacity but rather to a more efficient use of model parameters.
```

39. Songsri-in K, Zafeiriou S. Complement face forensic detection and localization with faciallandmarks. arXiv preprint arXiv:1910. 05455, 2019.

Link : https://arxiv.org/abs/1910.05455

Note : 利用人脸关键点信息提升性能的结论也被 Songsri-in 等人实验证实

```
Recently, Generative Adversarial Networks (GANs) and image manipulating methods are becoming more powerful and can produce highly realistic face images beyond human recognition which have raised significant concerns regarding the authenticity of digital media. 

Although there have been some prior works that tackle face forensic classification problem, it is not trivial to estimate edited locations from classification predictions. 

In this paper, we propose, to the best of our knowledge, the first rigorous face forensic localization dataset, which consists of genuine, generated, and manipulated face images. 

In particular, the pristine parts contain face images from CelebA and FFHQ datasets. The fake images are generated from various GANs methods, namely DCGANs, LSGANs, BEGANs, WGAN-GP, ProGANs, and StyleGANs. Lastly, the edited subset is generated from StarGAN and SEFCGAN based on free-form masks. 

In total, the dataset contains about 1.3 million facial images labelled with corresponding binary masks.

Based on the proposed dataset, we demonstrated that explicit adding facial landmarks information in addition to input images improves the performance. 

In addition, our proposed method consists of two branches and can coherently predict face forensic detection and localization to outperform the previous state-of-the-art techniques on the newly proposed dataset as well as the faceforecsic++ dataset especially on low-quality videos.
```

40. Nguyen HH, Yamagishi J, Echizen I. Capsule-forensics: Using capsule networks to detect forged images and videos. In: Proc. of the IEEE Int’l Conf. on Acoustics, Speech and Signal Processing (ICASSP 2019). IEEE, 2019. 2307−2311.

Link : https://arxiv.org/pdf/1810.11215.pdf?ref=https://githubhelp.com

Note : Nguyen 等人设计了胶囊网络来判别造假的图片或视频,通过抽取人脸,用 VGG-19 提取特征编码,然后输入胶囊网络进行分类.

```
Recent advances in media generation techniques have made it easier for attackers to create forged images and videos. 

Stateof-the-art methods enable the real-time creation of a forged version of a single video obtained from a social network. 

Although numerous methods have been developed for detecting forged images and videos, they are generally targeted at certain domains and quickly become obsolete as new kinds of attacks appear. 

The method introduced in this paper uses a capsule network to detect various kinds of spoofs, from replay attacks using printed images or recorded videos to computergenerated videos using deep convolutional neural networks.

It extends the application of capsule networks beyond their original intention to the solving of inverse graphics problems.
```

41. Simonyan K, Zisserman A. Very deep convolutional networks for large-scale image recognition. In: Proc. of the 3rd Int’l Conf. on Learning Representations (ICLR). 2015.

Link : https://arxiv.org/abs/1409.1556

Note : VGG-19

```
In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. 

Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. 

These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. 

We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. 

We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.
```

42. Mo H, Chen B, Luo W. Fake faces identification via convolutional neural network. In: Proc. of the 6th ACM Workshop on Information Hiding and Multimedia Security. 2018. 43−47.

Link : https://dl.acm.org/doi/10.1145/3206004.3206009

Note : Mo 等人增加高通滤波和背景作为 CNN 输入,对检测结果有提升.

```
Generative Adversarial Network (GAN) is a prominent generative model that are widely used in various applications. 

Recent studies have indicated that it is possible to obtain fake face images with a high visual quality based on this novel model. 

If those fake faces are abused in image tampering, it would cause some potential moral, ethical and legal problems. 

In this paper, therefore, we first propose a Convolutional Neural Network (CNN) based method to identify fake face images generated by the current best method, and provide experimental evidences to show that the proposed method can achieve satisfactory results with an average accuracy over 99.4%. 

In addition, we provide comparative results evaluated on some variants of the proposed CNN architecture, including the high pass filter, the number of the layer groups and the activation function, to further verify the rationality of our method.
```

43. Durall R, Keuper M, Pfreundt FJ, Keuper J. Unmasking DeepFakes with simple features. arXiv preprint arXiv:1911.00686, 2019.

Link : https://arxiv.org/abs/1911.00686

Note : Durall 等人通过离散傅里叶变换提取特征学习,显示了很好的效果.

```
Deep generative models have recently achieved impressive results for many real-world applications, successfully generating high-resolution and diverse samples from complex datasets. 

Due to this improvement, fake digital contents have proliferated growing concern and spreading distrust in image content, leading to an urgent need for automated ways to detect these AI-generated fake images.

Despite the fact that many face editing algorithms seem to produce realistic human faces, upon closer examination, they do exhibit artifacts in certain domains which are often hidden to the naked eye. 

In this work, we present a simple way to detect such fake face images - so-called DeepFakes. Our method is based on a classical frequency domain analysis followed by basic classifier. 

Compared to previous systems, which need to be fed with large amounts of labeled data, our approach showed very good results using only a few annotated training samples and even achieved good accuracies in fully unsupervised scenarios. 

For the evaluation on high resolution face images, we combined several public datasets of real and fake faces into a new benchmark: Faces-HQ. Given such high-resolution images, our approach reaches a perfect classification accuracy of 100% when it is trained on as little as 20 annotated samples. 

In a second experiment, in the evaluation of the medium-resolution images of the CelebA dataset, our method achieves 100% accuracy supervised and 96% in an unsupervised setting. 

Finally, evaluating a low-resolution video sequences of the FaceForensics++ dataset, our method achieves 91% accuracy detecting manipulated videos.
```

44. Ding X, Raziei Z, Larson EC, Olinick EV, Krueger PS, Hahsler M. Swapped face detection using deep learning and subjective assessment. EURASIP Journal on Information Security, 2020(2020):Article No.6.

Link : https://jis-eurasipjournals.springeropen.com/articles/10.1186/s13635-020-00109-8

Note : Ding 等人利用迁移学习,使用 Resnet18 进行调优;同时对于这些部署的关键系统,对每个预测提供一个不确定水平,如每个神经网层络输出值差异

```
The tremendous success of deep learning for imaging applications has resulted in numerous beneficial advances. 

Unfortunately, this success has also been a catalyst for malicious uses such as photo-realistic face swapping of parties without consent. 

In this study, we use deep transfer learning for face swapping detection, showing true positive rates greater than 96% with very few false alarms. 

Distinguished from existing methods that only provide detection accuracy, we also provide uncertainty for each prediction, which is critical for trust in the deployment of such detection systems. 

Moreover, we provide a comparison to human subjects. 

To capture human recognition performance, we build a website to collect pairwise comparisons of images from human subjects. 

Based on these comparisons, we infer a consensus ranking from the image perceived as most real to the image perceived as most fake. 

Overall, the results show the effectiveness of our method. 

As part of this study, we create a novel dataset that is, to the best of our knowledge, the largest swapped face dataset created using still images. 

This dataset will be available for academic research use per request. 

Our goal of this study is to inspire more research in the field of image forensics through the creation of a dataset and initial analysis.
```

45. Cozzolino D, Thies J, Rössler A, Riess C, Niebner M, Verdoliva L. Forensictransfer: Weakly-supervised domain adaptation for forgery detection. arXiv preprint arXiv:1812.02510, 2018.

Link : https://arxiv.org/abs/1812.02510

Note : Cozzolino 等人设计了一个新的基于自动编码器的神经网络结构,能够学习在不同的扰动域下的编码能力,只需要在一个数据集上训练,在另一个数据集上获取小规模进行调优,就能达到很好的效果.

```
Distinguishing manipulated from real images is becoming increasingly difficult as new sophisticated image forgery approaches come out by the day. 

Naive classification approaches based on Convolutional Neural Networks (CNNs) show excellent performance in detecting image manipulations when they are trained on a specific forgery method. 

However, on examples from unseen manipulation approaches, their performance drops significantly. 

To address this limitation in transferability, we introduce Forensic-Transfer (FT). 

We devise a learning-based forensic detector which adapts well to new domains, i.e., novel manipulation methods and can handle scenarios where only a handful of fake examples are available during training. 

To this end, we learn a forensic embedding based on a novel autoencoder-based architecture that can be used to distinguish between real and fake imagery. 

The learned embedding acts as a form of anomaly detector; namely, an image manipulated from an unseen method will be detected as fake provided it maps sufficiently far away from the cluster of real images. 

Comparing to prior works, FT shows significant improvements in transferability, which we demonstrate in a series of experiments on cutting-edge benchmarks. 

For instance, on unseen examples, we achieve up to 85% in terms of accuracy, and with only a handful of seen examples, our performance already reaches around 95%.
```

46. Nguyen HH, Fang F, Yamagishi J, Echizen I. Multi-task learning for detecting and segmenting manipulated facial images and videos. arXiv preprint arXiv:1906.06876, 2019.

Link : https://arxiv.org/abs/1906.06876

Note : Nguyen 等人设计了 Y 型解码器,在分类的同时融入分割和重建损失,通过分割辅助分类效果

```
Detecting manipulated images and videos is an important topic in digital media forensics. 

Most detection methods use binary classification to determine the probability of a query being manipulated. 

Another important topic is locating manipulated regions (i.e., performing segmentation), which are mostly created by three commonly used attacks: removal, copy-move, and splicing. 

We have designed a convolutional neural network that uses the multi-task learning approach to simultaneously detect manipulated images and videos and locate the manipulated regions for each query. 

Information gained by performing one task is shared with the other task and thereby enhance the performance of both tasks. 

A semi-supervised learning approach is used to improve the network's generability. 

The network includes an encoder and a Y-shaped decoder. Activation of the encoded features is used for the binary classification. 

The output of one branch of the decoder is used for segmenting the manipulated regions while that of the other branch is used for reconstructing the input, which helps improve overall performance. 

Experiments using the FaceForensics and FaceForensics++ databases demonstrated the network's effectiveness against facial reenactment attacks and face swapping attacks as well as its ability to deal with the mismatch condition for previously seen attacks. 

Moreover, fine-tuning using just a small amount of data enables the network to deal with unseen attacks.

```

47. Hsu CC, Lee CY, Zhuang YX. Learning to detect fake face images in the wild. In: Proc. of the Int’l Symp. on Computer, Consumer and Control (IS3C). IEEE, 2018. 388−391.

Link : https://arxiv.org/abs/1809.08754

Note : Hsu 等人采用对比损失寻找不同生成器生成的图像的特征,后面再连接一个分类器进行分类

```
Although Generative Adversarial Network (GAN) can be used to generate the realistic image, improper use of these technologies brings hidden concerns. 

For example, GAN can be used to generate a tampered video for specific people and inappropriate events, creating images that are detrimental to a particular person, and may even affect that personal safety. 

In this paper, we will develop a deep forgery discriminator (DeepFD) to efficiently and effectively detect the computer-generated images. 

Directly learning a binary classifier is relatively tricky since it is hard to find the common discriminative features for judging the fake images generated from different GANs. 

To address this shortcoming, we adopt contrastive loss in seeking the typical features of the synthesized images generated by different GANs and follow by concatenating a classifier to detect such computer-generated images. 

Experimental results demonstrate that the proposed DeepFD successfully detected 94.7% fake images generated by several state-of-the-art GANs.
```

48. Hsu CC, Zhuang YX, Lee CY. Deep fake image detection based on pairwise learning. Applied Sciences, 2020,10(1):Article No.370.

Link : https://www.researchgate.net/publication/338382561_Deep_Fake_Image_Detection_Based_on_Pairwise_Learning

Note : Hsu 等人采用对比损失寻找不同生成器生成的图像的特征,后面再连接一个分类器进行分类

```
Generative adversarial networks (GANs) can be used to generate a photo-realistic image from a low-dimension random noise. 

Such a synthesized (fake) image with inappropriate content can be used on social media networks, which can cause severe problems. 

With the aim to successfully detect fake images, an effective and efficient image forgery detector is necessary. 

However, conventional image forgery detectors fail to recognize fake images generated by the GAN-based generator since these images are generated and manipulated from the source image. 

Therefore, in this paper, we propose a deep learning-based approach for detecting the fake images by using the contrastive loss. 

First, several state-of-the-art GANs are employed to generate the fake–real image pairs. Next, the reduced DenseNet is developed to a two-streamed network structure to allow pairwise information as the input. 

Then, the proposed common fake feature network is trained using the pairwise learning to distinguish the features between the fake and real images. 

Finally, a classification layer is concatenated to the proposed common fake feature network to detect whether the input image is fake or real. 

The experimental results demonstrated that the proposed method significantly outperformed other state-of-the-art fake image detectors.
```

49. Dang LM, Hassan SI, Im S, Lee J, Lee S, Moon H. Deep learning based computer generated face identification using convolutional neural network. Applied Sciences, 2018,8(12):Article No.2610.

Link : https://www.researchgate.net/publication/329652579_Deep_Learning_Based_Computer_Generated_Face_Identification_Using_Convolutional_Neural_Network

Note : Dang 等人设计了特定的 CGFace 网路,专门检测计算机生成的人脸;

```
Generative adversarial networks (GANs) describe an emerging generative model which has made impressive progress in the last few years in generating photorealistic facial images. 

As the result, it has become more and more difficult to differentiate between computer-generated and real face images, even with the human’s eyes. 

If the generated images are used with the intent to mislead and deceive readers, it would probably cause severe ethical, moral, and legal issues. 

Moreover, it is challenging to collect a dataset for computer-generated face identification that is large enough for research purposes because the number of realistic computer-generated images is still limited and scattered on the internet. 

Thus, a development of a novel decision support system for analyzing and detecting computer-generated face images generated by the GAN network is crucial. 

In this paper, we propose a customized convolutional neural network, namely CGFace, which is specifically designed for the computer-generated face detection task by customizing the number of convolutional layers, so it performs well in detecting computer-generated face images. 

After that, an imbalanced framework (IF-CGFace) is created by altering CGFace’s layer structure to adjust to the imbalanced data issue by extracting features from CGFace layers and use them to train AdaBoost and eXtreme Gradient Boosting (XGB). 

Next, we explain the process of generating a large computer-generated dataset based on the state-of-the-art PCGAN and BEGAN model. 

Then, various experiments are carried out to show that the proposed model with augmented input yields the highest accuracy at 98%. 

Finally, we provided comparative results by applying the proposed CNN architecture on images generated by other GAN researches.
```

50. Bayar B, Stamm MC. A deep learning approach to universal image manipulation detection using a new convolutional layer. In: Proc. of the 4th ACM Workshop on Information Hiding and Multimedia Security. 2016. 5−10.

Link : https://misl.ece.drexel.edu/wp-content/uploads/2017/07/Bayar_IHMMSec_2016.pdf

Note : Bayar 等人设计了受限制的卷积层学习特定的篡改特征

```
When creating a forgery, a forger can modify an image using many different image editing operations. 

Since a forensic examiner must test for each of these, significant interest has arisen in the development of universal forensic algorithms capable of detecting many different image editing operations and manipulations. 

In this paper, we propose a universal forensic approach to performing manipulation detection using deep learning. 

Specifically, we propose a new convolutional network architecture capable of automatically learning manipulation detection features directly from training data. 

In their current form, convolutional neural networks will learn features that capture an image’s content as opposed to manipulation detection features. 

To overcome this issue, we develop a new form of convolutional layer that is specifically designed to suppress an image’s content and adaptively learn manipulation detection features. 

Through a series of experiments, we demonstrate that our proposed approach can automatically learn how to detect multiple image manipulations without relying on pre-selected features or any preprocessing. 

The results of these experiments show that our proposed approach can automatically detect several different manipulations with an average accuracy of 99.10%.
```

51. Dang H, Liu F, Stehouwer J, Liu X, Jain A. On the detection of digital face manipulation. In: Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). 2020. 5780−5789.

Link : https://arxiv.org/abs/1910.01717

Note : CNN+Attention, 增加注意力机制, DFFD,;Stehouwer 等人通过在主干网络增加注意力机制来聚焦篡改区域;

```
Detecting manipulated facial images and videos is an increasingly important topic in digital media forensics. 

As advanced face synthesis and manipulation methods are made available, new types of fake face representations are being created which have raised significant concerns for their use in social media. 

Hence, it is crucial to detect manipulated face images and localize manipulated regions. 

Instead of simply using multi-task learning to simultaneously detect manipulated images and predict the manipulated mask (regions), we propose to utilize an attention mechanism to process and improve the feature maps for the classification task. 

The learned attention maps highlight the informative regions to further improve the binary classification (genuine face v. fake face), and also visualize the manipulated regions. 

To enable our study of manipulated face detection and localization, we collect a large-scale database that contains numerous types of facial forgeries. 

With this dataset, we perform a thorough analysis of data-driven fake face detection. 

We show that the use of an attention mechanism improves facial forgery detection and manipulated region localization.
```

52. Rahmouni N, Nozick V, Yamagishi J, Echizen I. Distinguishing computer graphics from natural images using convolution neural networks. In: Proc. of the IEEE Workshop on Information Forensics and Security (WIFS). IEEE, 2017. 1−6.

Link : http://www-igm.univ-mlv.fr/~vnozick/publications/Rahmouni_WIFS_2017/Rahmouni_WIFS_2017.pdf

Note : Rahmouni 等人加入了计算统计数据的全局池化层.

```
This paper presents a deep-learning method for distinguishing computer generated graphics from real photographic images. 

The proposed method uses a Convolutional Neural Network (CNN) with a custom pooling layer to optimize current best-performing algorithms feature extraction scheme. 

Local estimates of class probabilities are computed and aggregated to predict the label of the whole picture. 

We evaluate our work on recent photo-realistic computer graphics and show that it outperforms state of the art methods for both local and full image classification.
```

53. Li X, Yu K, Ji S, Wang Y, Wu C, Xue H. Fighting against Deepfake: Patch&Pair convolutional neural networks (PPCNN). In: Proc. of the Companion Web Conf. 2020. 2020. 88−89.

Link : https://dl.acm.org/doi/fullHtml/10.1145/3366424.3382711

Note : 设计了基于图片块的双流网路框架,一条流学习人脸块的微观特征,另一条流学习人脸和背景区域的差异性.通过多任务学习,能够较好地提升模型的泛化能力. 

```
In this paper, we propose a novel Patch&Pair Convolutional Neural Networks (PPCNN) to distinguish Deepfake videos or images from real ones. 

Through the comprehensive evaluations on public datasets, we demonstrate that our model performs better than existing detection methods and show better generalization.
```

54. Brockschmidt J, Shang J, Wu J. On the generality of facial forgery detection. In: Proc. of the IEEE 16th Int’l Conf. on Mobile Ad Hoc and Sensor Systems Workshops (MASSW). IEEE, 2019. 43−47.

Link : https://ieeexplore.ieee.org/document/9059392

Note : 学习篡改图片的特点可行且高效.此类方法不仅可以判断单帧图像的真伪,还可以利用组合策略检测视频帧,应用范围较广,但是也存在很多局限性,学习到的模型大多数依赖相同的数据分布,在面对未知篡改类型时
很乏力

```
A variety of architectures have been designed or repurposed for the task of facial forgery detection. 

While many of these designs have seen great success, they largely fail to address challenges these models may face in practice. 

A major challenge is posed by generality, wherein models must be prepared to perform in a variety of domains. 

In this paper, we investigate the ability of state-of-the-art facial forgery detection architectures to generalize. 

We first propose two criteria for generality: reliably detecting multiple spoofing techniques and reliably detecting unseen spoofing techniques. 

We then devise experiments which measure how a given architecture performs against these criteria. 

Our analysis focuses on two state-of-the-art facial forgery detection architectures, MesoNet and XceptionNet, both being convolutional neural networks (CNNs). 

Our experiments use samples from six state-of-the-art facial forgery techniques: Deepfakes, Face2Face, FaceSwap, GANnotation, ICface, and X2Face. 

We find MesoNet and XceptionNet show potential to generalize to multiple spoofing techniques but with a slight trade-off in accuracy, and largely fail against unseen techniques. 

We loosely extrapolate these results to similar CNN architectures and emphasize the need for better architectures to meet the challenges of generality.
```

55. Sohrawardi SJ, Chintha A, Thai B, Seng S, Hickerson A, Ptucha R, Wright M. Poster: Towards robust open-world detection of Deepfakes. In: Proc. of the ACM SIGSAC Conf. on Computer and Communications Security. 2019. 2613−2615.

Link : https://www.researchgate.net/publication/337092099_Poster_Towards_Robust_Open-World_Detection_of_Deepfakes

Note : 学习篡改图片的特点可行且高效.此类方法不仅可以判断单帧图像的真伪,还可以利用组合策略检测视频帧,应用范围较广,但是也存在很多局限性,学习到的模型大多数依赖相同的数据分布,在面对未知篡改类型时很乏力

```
There is heightened concern over deliberately inaccurate news. 

Recently, so-called deepfake videos and images that are modified by or generated by artificial intelligence techniques have become more realistic and easier to create. 

These techniques could be used to create fake announcements from public figures or videos of events that did not happen, misleading mass audiences in dangerous ways. 

Although some recent research has examined accurate detection of deepfakes, those methodologies do not generalize well to real-world scenarios and are not available to the public in a usable form. 

In this project, we propose a system that will robustly and efficiently enable users to determine whether or not a video posted online is a deepfake. 

We approach the problem from the journalists' perspective and work towards developing a tool to fit seamlessly into their workflow. 

Results demonstrate accurate detection on both within and mismatched datasets.
```

56. Agarwal S, Farid H, Gu Y, He M, Nagano K, Li H. Protecting world leaders against deep fakes. In: Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition Workshops. 2019. 38−45.

Link : https://openaccess.thecvf.com/content_CVPRW_2019/papers/Media%20Forensics/Agarwal_Protecting_World_Leaders_Against_Deep_Fakes_CVPRW_2019_paper.pdf

Note : 5]发现:作为个体,他们有不一致的面部表情和移动,通过追踪面部和头部移动然后抽取特定动作集合的存在和强度,脸部肌肉的移动可以编码成动作单元,再利用皮尔森系数对特征之间的相关性进行扩充,最后在扩充后的特征集合上建立一个新的单分类 SVM 来区分各类造假视频.然而实验结果显示:虽然 AUC 达到 0.9 以上,但是召回普遍不高,实用性较差

```
The creation of sophisticated fake videos has been largely relegated to Hollywood studios or state actors. 

Recent advances in deep learning, however, have made it significantly easier to create sophisticated and compelling fake videos. 

With relatively modest amounts of data and computing power, the average person can, for example, create a video of a world leader confessing to illegal activity leading
to a constitutional crisis, a military leader saying something racially insensitive leading to civil unrest in an area of military activity, or a corporate titan claiming that their profits are weak leading to global stock manipulation. 

These so called deep fakes pose a significant threat to our democracy, national security, and society. 

To contend with this growing threat, we describe a forensic technique that models facial expressions and movements that typify an individual’s speaking pattern.

Although not visually apparent, these correlations are often violated by the nature of how deep-fake videos are created and can, therefore, be used for authentication
```

57. Amerini I, Galteri L, Caldelli R, Bimbo AD. Deepfake video detection through optical flow based CNN. In: Proc. of the IEEE Int’l Conf. on Computer Vision Workshops. 2019. 1205−1207.

Link : https://openaccess.thecvf.com/content_ICCVW_2019/papers/HBU/Amerini_Deepfake_Video_Detection_through_Optical_Flow_Based_CNN_ICCVW_2019_paper.pdf

Note : 探索帧间光流的不同,采用 VGG16 学习光流的差异并进行分类,因为光流是连续帧间的运动差异计算的,自然拍摄和伪造的视频之间的运动差异很大. 

```
Recent advances in visual media technology have led to new tools for processing and, above all, generating multimedia contents. 

In particular, modern AI-based technologies have provided easy-to-use tools to create extremely realistic manipulated videos. 

Such synthetic videos, named Deep Fakes, may constitute a serious threat to attack the reputation of public subjects or to address the general opinion on a certain event. According to this, being able to individuate this kind of fake information becomes fundamental.

In this work, a new forensic technique able to discern between fake and original video sequences is given; unlike other state-of-the-art methods which resorts at single video frames, we propose the adoption of optical flow fields to exploit possible inter-frame dissimilarities. 

Such a clue is then used as feature to be learned by CNN classifiers. Preliminary results obtained on FaceForensics++ dataset highlight very promising performances.
```

58. Güera D, Delp EJ. Deepfake video detection using recurrent neural networks. In: Proc. of the 15th IEEE Int’l Conf. on Advanced Video and Signal Based Surveillance (AVSS). IEEE, 2018. 1−6.

Link : https://ieeexplore.ieee.org/document/8639163

Note : 考虑用循环神经网络处理深度伪造的序列数据,因为多个相机视角,光照条件的不同,不同的视频压缩率使得生成器很难产生实际真实的在不同条件下的脸,这个会导致交换的脸在剩下的场景下看起来不一致.
此外,因为生成器没办法意识到皮肤或者其他场景信息,所以新脸和剩下帧之间的融合性差,不同帧场景间的光源会引起大多数脸部闪烁现象,这个可以被时序网络较好地捕捉到.

```
In recent months a machine learning based free software tool has made it easy to create believable face swaps in videos that leaves few traces of manipulation, in what are known as "deepfake" videos. 

Scenarios where these realistic fake videos are used to create political distress, blackmail someone or fake terrorism events are easily envisioned. 

This paper proposes a temporal-aware pipeline to automatically detect deepfake videos. Our system uses a convolutional neural network (CNN) to extract frame-level features. 

These features are then used to train a recurrent neural network (RNN) that learns to classify if a video has been subject to manipulation or not. 

We evaluate our method against a large set of deepfake videos collected from multiple video websites. 

We show how our system can achieve competitive results in this task while using a simple architecture.
```

59. Sabir E, Cheng J, Jaiswal A, AbdAlmageed W, Masi I, Natarajan P. Recurrent convolutional strategies for face manipulation detection in videos. arXiv preprint arXiv:1905.00582, 2019.

Link : https://arxiv.org/abs/1905.00582

Note : CNN+Bi-LSTM, 图片的时序信息, FF++/LQ/DF/F2F/FS,采用双向时序网络和人脸对齐结合的方法学习伪造序列,结果显示,基于关键点的人脸对齐与 Bidrectional-recurrent-denset 对视频的篡改检测最佳

```
The spread of misinformation through synthetically generated yet realistic images and videos has become a significant problem, calling for robust manipulation detection methods.

Despite the predominant effort of detecting face manipulation in still images, less attention has been paid to the identification of tampered faces in videos by taking advantage of the temporal information present in the stream.

Recurrent convolutional models are a class of deep learning models which have proven effective at exploiting the temporal information from image streams across domains. 

We thereby distill the best strategy for combining variations in these models along with domain specific face preprocessing techniques through extensive experimentation to obtain state-of-the-art performance on publicly available video-based facial manipulation benchmarks. 

Specifically, we attempt to detect Deepfake, Face2Face and FaceSwap tampered faces in video streams. 

Evaluation is performed on the recently introduced FaceForensics++ dataset, improving the previous state-of-the-art by up to 4.55% in accuracy.
```

60. Todisco M, Delgado H, Evans NWD. A new feature for automatic speaker verification anti-spoofing: Constant Q cepstral coefficients. In: Proc. of the Odyssey. 2016. 283−290.

Link : https://www.eurecom.fr/publication/4855

Note : Todisco 等人提出的常量 Q 倒谱系数(constant-Q cepstral coefficients,简称 CQCC)

```
Efforts to develop new countermeasures in order to protect automatic speaker verification from spoofing have intensified over recent years. 

The ASVspoof 2015 initiative showed that there is great potential to detect spoofing attacks, but also that the detection of previously unforeseen spoofing attacks remains challenging. 

This paper argues that there is more to be gained from the study of features rather than classifiers and introduces a new feature for spoofing detection based on the constant Q transform, a perceptually-inspired time-frequency analysis tool popular in the study of music. 

Experimental results obtained using the standard ASVspoof 2015 database show that, when coupled with a standard Gaussian mixture model-based classifier, the proposed constant Q cepstral coefficients (CQCCs) outperform all previously reported results by a significant margin. 

In particular, those for a subset of unknown spoofing attacks (for which no matched training data was used) is 0.46%, a relative improvement of 72% over the best, previously reported results. 
```

61. Rössler A, Cozzolino D, Verdoliva L, Christian R, Justus T, Matthias N. Faceforensics: A large-scale video dataset for forgery detection in human faces. arXiv preprint arXiv:1803.09179, 2018.

Link : https://arxiv.org/abs/1803.09179

Note : Open source dataset of the Deepfake - 深度伪造开源数据集;FaceForensics(FF) Face2Face FaceForensics++的前身,只有一种篡改类型

```
With recent advances in computer vision and graphics, it is now possible to generate videos with extremely realistic synthetic faces, even in real time. 

Countless applications are possible, some of which raise a legitimate alarm, calling for reliable detectors of fake videos. 

In fact, distinguishing between original and manipulated video can be a challenge for humans and computers alike, especially when the videos are compressed or have low resolution, as it often happens on social networks. 

Research on the detection of face manipulations has been seriously hampered by the lack of adequate datasets. 

To this end, we introduce a novel face manipulation dataset of about half a million edited images (from over 1000 videos). 

The manipulations have been generated with a state-of-the-art face editing approach. 

It exceeds all existing video manipulation datasets by at least an order of magnitude. 

Using our new dataset, we introduce benchmarks for classical image forensic tasks, including classification and segmentation, considering videos compressed at various quality levels. 

In addition, we introduce a benchmark evaluation for creating indistinguishable forgeries with known ground truth; for instance with generative refinement models.
```

62. Rossler A, Cozzolino D, Verdoliva L, Riess C, Thies J, Niessner M. Faceforensics++: Learning to detect manipulated facial images. In: Proc. of the IEEE Int’l Conf. on Computer Vision. 2019. 1−11.

Link : https://arxiv.org/abs/1901.08971

Note : FaceForensics++(FF++),Deepfakes,FaceSwap,Face2face,Neuraltexture; 每一类篡改视频均被 C0,C23,C40 这 3 种参数压缩

```
The rapid progress in synthetic image generation and manipulation has now come to a point where it raises significant concerns for the implications towards society. 

At best, this leads to a loss of trust in digital content, but could potentially cause further harm by spreading false information or fake news. 

This paper examines the realism of state-of-the-art image manipulations, and how difficult it is to detect them, either automatically or by humans. 

To standardize the evaluation of detection methods, we propose an automated benchmark for facial manipulation detection. 

In particular, the benchmark is based on DeepFakes, Face2Face, FaceSwap and NeuralTextures as prominent representatives for facial manipulations at random compression level and size. 

The benchmark is publicly available and contains a hidden test set as well as a database of over 1.8 million manipulated images. 

This dataset is over an order of magnitude larger than comparable, publicly available, forgery datasets. 

Based on this data, we performed a thorough analysis of data-driven forgery detectors. 

We show that the use of additional domainspecific knowledge improves forgery detection to unprecedented accuracy, even in the presence of strong compression, and clearly outperforms human observers.
```

63. Korshunov P, Marcel S. Deepfakes: A new threat to face recognition? Assessment and detection. arXiv preprint arXiv:1812.08685, 2018.

Link : https://arxiv.org/abs/1812.08685

Note : DeepfakeTIMIT,faceswapGAN,GAN 版本 Deepfakes 换脸.有高清和低清两个版本

```
It is becoming increasingly easy to automatically replace a face of one person in a video with the face of another person by using a pre-trained generative adversarial network (GAN). 

Recent public scandals, e.g., the faces of celebrities being swapped onto pornographic videos, call for automated ways to detect these Deepfake videos. 

To help developing such methods, in this paper, we present the first publicly available set of Deepfake videos generated from videos of VidTIMIT database. 

We used open source software based on GANs to create the Deepfakes, and we emphasize that training and blending parameters can significantly impact the quality of the resulted videos. 

To demonstrate this impact, we generated videos with low and high visual quality (320 videos each) using differently tuned parameter sets. 

We showed that the state of the art face recognition systems based on VGG and Facenet neural networks are vulnerable to Deepfake videos, with 85.62% and 95.00% false acceptance rates respectively, which means methods for detecting Deepfake videos are necessary. 

By considering several baseline approaches, we found that audio-visual approach based on lip-sync inconsistency detection was not able to distinguish Deepfake videos. 

The best performing method, which is based on visual quality metrics and is often used in presentation attack detection domain, resulted in 8.97% equal error rate on high quality Deepfakes. 

Our experiments demonstrate that GAN-generated Deepfake videos are challenging for both face recognition systems and existing detection methods, and the further development of face swapping technology will make it even more so.
```

64. VidTIMIT. 2019. http://conradsanderson.id.au/vidtimit/

Link : http://conradsanderson.id.au/vidtimit/

Note : 深度伪造开源数据集 VidTIMIT 获取源


65. Afchar D, Nozick V, Yamagishi J, Echizen I. Mesonet: A compact facial video forgery detection network. In: Proc. of the IEEE Int’l Workshop on Information Forensics and Security (WIFS). IEEE, 2018. 1−7.

Link : https://arxiv.org/abs/1809.00888

Note : 深度伪造开源数据集, Mesonet data

```
This paper presents a method to automatically and efficiently detect face tampering in videos, and particularly focuses on two recent techniques used to generate hyper-realistic forged videos: Deepfake and Face2Face. 

Traditional image forensics techniques are usually not well suited to videos due to the compression that strongly degrades the data. 

Thus, this paper follows a deep learning approach and presents two networks, both with a low number of layers to focus on the mesoscopic properties of images. 

We evaluate those fast networks on both an existing dataset and a dataset we have constituted from online videos. 

The tests demonstrate a very successful detection rate with more than 98% for Deepfake and 95% for Face2Face.
```

66. Li Y, Yang X, Sun P, Qi H, Lyu S. Celeb-DF: A new dataset for Deepfake forensics. arXiv preprint arXiv:1909.12962, 2019.

Link : https://arxiv.org/abs/1909.12962

Note : 深度伪造开源数据集,Celeb-DF, Deepfakes 针对过去伪造视频的质量差、不稳定等缺点进行改进,效果更好

```
AI-synthesized face-swapping videos, commonly known as DeepFakes, is an emerging problem threatening the trustworthiness of online information. 

The need to develop and evaluate DeepFake detection algorithms calls for large-scale datasets. 

However, current DeepFake datasets suffer from low visual quality and do not resemble DeepFake videos circulated on the Internet. 

We present a new large-scale challenging DeepFake video dataset, Celeb-DF, which contains 5,639 high-quality DeepFake videos of celebrities generated using improved synthesis process. 

We conduct a comprehensive evaluation of DeepFake detection methods and datasets to demonstrate the escalated level of challenges posed by Celeb-DF.
```

67. DeepfakeDetection. 2019. https://github.com/ondyari/FaceForensics

Link : https://github.com/ondyari/FaceForensics

Note : 深度伪造开源数据集,DeepfakeDetection(DFD),363 个不同场景下的原视频,然后进行换脸.篡改视频均 C0,C23,C40 这 3 种参数压缩


68. Dolhansky B, Howes R, Pflaum B, Baram N, Ferrer C. The Deepfake detection challenge (DFDC) preview dataset. arXiv preprint arXiv:1910.08854, 2019.

Link : https://arxiv.org/abs/1910.08854

Note : 深度伪造开源数据集,DFDC preview dataset Unknown Deepfakes 竞赛的预赛数据

```

In this paper, we introduce a preview of the Deepfakes Detection Challenge (DFDC) dataset consisting of 5K videos featuring two facial modification algorithms. 

A data collection campaign has been carried out where participating actors have entered into an agreement to the use and manipulation of their likenesses in our creation of the dataset. 

Diversity in several axes (gender, skin-tone, age, etc.) has been considered and actors recorded videos with arbitrary backgrounds thus bringing visual variability. 

Finally, a set of specific metrics to evaluate the performance have been defined and two existing models for detecting deepfakes have been tested to provide a reference performance baseline. 

The DFDC dataset preview can be downloaded at: this http URL(http://deepfakedetectionchallenge.ai/)
```

69. DFDC. 2020. https://www.kaggle.com/c/deepfake-detection-challenge/data

Link : https://www.kaggle.com/c/deepfake-detection-challenge/data

Note : DFDC Unknown Deepfakes 竞赛的正式全部数据

70. Jiang L, Li R, Wu W, Qian C, Loy C. DeeperForensics-1.0: A large-scale dataset for real-world face forgery detection. In: Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). 2020. 2886−2895.

Link : https://openaccess.thecvf.com/content_CVPR_2020/html/Jiang_DeeperForensics-1.0_A_Large-Scale_Dataset_for_Real-World_Face_Forgery_Detection_CVPR_2020_paper.html

https://github.com/EndlessSora/DeeperForensics-1.0

Note : 深度伪造开源数据集,DeeperForensics1.0,{DeepFake,Variational,Auto-Encoder}改进的生成

```
We present our on-going effort of constructing a large- scale benchmark for face forgery detection. 

The first version of this benchmark, DeeperForensics-1.0, represents the largest face forgery detection dataset by far, with 60, 000 videos constituted by a total of 17.6 million frames, 10 times larger than existing datasets of the same kind. 

Extensive real-world perturbations are applied to obtain a more challenging benchmark of larger scale and higher diversity. 

All source videos in DeeperForensics-1.0 are carefully collected, and fake videos are generated by a newly proposed end-to-end face swapping framework. 

The quality of generated videos outperforms those in existing datasets, validated by user studies. 

The benchmark features a hidden test set, which contains manipulated videos achieving high deceptive scores in human evaluations. 

We further contribute a comprehensive study that evaluates five representative detection baselines and make a thorough analysis of different settings.
```

71. ASVspoof 2015 database. 2020. https://datashare.is.ed.ac.uk/handle/10283/853

Link : https://datashare.is.ed.ac.uk/handle/10283/853

Note : 深度伪造开源数据集, synthetic and converted speech, 106 speakers



72. ASVspoof 2019 database. 2020. https://datashare.is.ed.ac.uk/handle/10283/3336

Link : https://datashare.is.ed.ac.uk/handle/10283/3336

Note : 深度伪造开源数据集, synthetic and converted speech, 107 speakers



73. Abu-El-Haija S, Kothari N, Lee J, Natsev P, Toderici G, Varadarajan B, Vijayanarasimhan S. Youtube-8m: A large-scale video classification benchmark. arXiv preprint arXiv:1609.08675, 2016.

Link : https://arxiv.org/abs/1609.08675

Note : Youtube8M,选取该数据集中标签为人脸、新闻播报员、新闻联播的视频以及 YouTube 上有类似标签的视频共 1 004 个,所有选取的视频分辨率大于 480p.

除此之外,作者用人脸检测器抽取视频中的人脸序列,确保所选视频连续 300 帧中含有人脸,并手动过滤掉人脸遮挡过多的视频以确保视频质量.

最后,采用 Face2Face 的换表情的方法构造 1 004 个假视频.此数据集视频规模大、源视频人脸质量高,但是篡改痕迹明显,篡改方式单一. 

```
Many recent advancements in Computer Vision are attributed to large datasets. 

Open-source software packages for Machine Learning and inexpensive commodity hardware have reduced the barrier of entry for exploring novel approaches at scale. 

It is possible to train models over millions of examples within a few days. Although large-scale datasets exist for image understanding, such as ImageNet, there are no comparable size video classification datasets.

In this paper, we introduce YouTube-8M, the largest multi-label video classification dataset, composed of ~8 million videos (500K hours of video), annotated with a vocabulary of 4800 visual entities. 

To get the videos and their labels, we used a YouTube video annotation system, which labels videos with their main topics. 

While the labels are machine-generated, they have high-precision and are derived from a variety of human-based signals including metadata and query click signals. 

We filtered the video labels (Knowledge Graph entities) using both automated and manual curation strategies, including asking human raters if the labels are visually recognizable. 

Then, we decoded each video at one-frame-per-second, and used a Deep CNN pre-trained on ImageNet to extract the hidden representation immediately prior to the classification layer. 

Finally, we compressed the frame features and make both the features and video-level labels available for download.

We trained various (modest) classification models on the dataset, evaluated them using popular evaluation metrics, and report them as baselines. 

Despite the size of the dataset, some of our models train to convergence in less than a day on a single machine using TensorFlow. 

We plan to release code for training a TensorFlow model and for computing metrics.
```

74. Amerini I, Ballan L, Caldelli R, Bimbo AD, Serra G. A sift-based forensic method for copy-move attack detection and transformation recovery. IEEE Trans. on Information Forensics and Security, 2011,6(3):1099−1110.

Link : https://www.researchgate.net/publication/224225329_A_SIFT-Based_Forensic_Method_for_Copy-Move_Attack_Detection_and_Transformation_Recovery

Note : 传统的图像取证初始主要是基于传统的信号处理方法,大多数依赖于特定篡改的证据,利用图像的频域特征和统计特征进行区分,如局部噪音分析、图像质量评估、设备指纹、光照等,該篇解决复制-移动

```
One of the principal problems in image forensics is determining if a particular image is authentic or not. 

This can be a crucial task when images are used as basic evidence to influence judgment like, for example, in a court of law. 

To carry out such forensic analysis, various technological instruments have been developed in the literature. 

In this paper, the problem of detecting if an image has been forged is investigated; in particular, attention has been paid to the case in which an area of an image is copied and then pasted onto another zone to create a duplication or to cancel something that was awkward. 

Generally, to adapt the image patch to the new context a geometric transformation is needed. 

To detect such modifications, a novel methodology based on scale invariant features transform (SIFT) is proposed. Such a method allows us to both understand if a copy-move attack has occurred and, furthermore, to recover the geometric transformation used to perform cloning. 

Extensive experimental results are presented to confirm that the technique is able to precisely individuate the altered area and, in addition, to estimate the geometric transformation parameters with high reliability. 

The method also deals with multiple cloning.
```

75. De Carvalho TJ, Riess C, Angelopoulou E, Pedrini H, Rocha A. Exposing digital image forgeries by illumination color classification. IEEE Trans. on Information Forensics and Security, 2013,8(7):1182−1194.

Link : https://ieeexplore.ieee.org/document/6522874

Note : 传统的图像取证初始主要是基于传统的信号处理方法,大多数依赖于特定篡改的证据,利用图像的频域特征和统计特征进行区分,如局部噪音分析、图像质量评估、设备指纹、光照等,該篇解决拼接

```
For decades, photographs have been used to document space-time events and they have often served as evidence in courts. 

Although photographers are able to create composites of analog pictures, this process is very time consuming and requires expert knowledge. 

Today, however, powerful digital image editing software makes image modifications straightforward. This undermines our trust in photographs and, in particular, questions pictures as evidence for real-world events. 

In this paper, we analyze one of the most common forms of photographic manipulation, known as image composition or splicing. 

We propose a forgery detection method that exploits subtle inconsistencies in the color of the illumination of images. Our approach is machine-learning-based and requires minimal user interaction. 

The technique is applicable to images containing two or more people and requires no expert interaction for the tampering decision. 

To achieve this, we incorporate information from physics- and statistical-based illuminant estimators on image regions of similar material. 

From these illuminant estimates, we extract texture- and edge-based features which are then provided to a machine-learning approach for automatic decision-making. 

The classification performance using an SVM meta-fusion classifier is promising. It yields detection rates of 86% on a new benchmark dataset consisting of 200 images, and 83% on 50 images that were collected from the Internet.
```

76. Lukáš J, Fridrich J, Goljan M. Detecting digital image forgeries using sensor pattern noise. In: Proc. of the Security, Steganography, and Watermarking of Multimedia Contents VIII, Vol.6072. Int’l Society for Optics and Photonics, 2006.

Link : https://www.spiedigitallibrary.org/conference-proceedings-of-spie/6072/60720Y/Detecting-digital-image-forgeries-using-sensor-pattern-noise/10.1117/12.640109.short?SSO=1

Note : Lukas 等人提出了数字图像的相机设备指纹光响应不均匀性(PRNU)

```
We present a new approach to detection of forgeries in digital images under the assumption that either the camera that took the image is available or other images taken by that camera are available. 

Our method is based on detecting the presence of the camera pattern noise, which is a unique stochastic characteristic of imaging sensors, in individual regions in the image. 

The forged region is determined as the one that lacks the pattern noise. 

The presence of the noise is established using correlation as in detection of spread spectrum watermarks. 

We proposed two approaches. 

In the first one, the user selects an area for integrity verification. 

The second method attempts to automatically determine the forged area without assuming any a priori knowledge. 

The methods are tested both on examples of real forgeries and on non-forged images. 

We also investigate how further image processing applied to the forged image, such as lossy compression or filtering, influences our ability to verify image integrity.
```

77. Chierchia G, Parrilli S, Poggi G, Verdoliva L, Sansone C. PRNU-based detection of small-size image forgeries. In: Proc. of the 17th Int’l Conf. on Digital Signal Processing (DSP). IEEE, 2011. 1−6. 

Link : https://ieeexplore.ieee.org/document/6004957

Note : Chierchia 等人进一步利用光响应不均匀性检测小的篡改图像

```
The Photo-Response Non-Uniformity (PRNU) has been recently introduced as a powerful tool to detect image forgeries. 

In spite of its effectiveness in many scenarios, the proposed method fails to detect small manipulations. 

In this work we propose a modified version of the detection algorithm described in, based on a preliminary segmentation of the image, which guarantees a better detection performance for small size additive forgeries.
```

78. Fridrich J, Kodovsky J. Rich models for steganalysis of digital images. IEEE Trans. on Information Forensics and Security, 2012, 7(3):868−882.

Link : https://ieeexplore.ieee.org/document/6197267

Note : Jessica 等人通过组装噪声分量模型提出了数字图像的隐写特征,随后,噪声特征被广泛运用在图像取证领域

```
We describe a novel general strategy for building steganography detectors for digital images. 

The process starts with assembling a rich model of the noise component as a union of many diverse submodels formed by joint distributions of neighboring samples from quantized image noise residuals obtained using linear and nonlinear high-pass filters. 

In contrast to previous approaches, we make the model assembly a part of the training process driven by samples drawn from the corresponding cover- and stego-sources. 

Ensemble classifiers are used to assemble the model as well as the final steganalyzer due to their low computational complexity and ability to efficiently work with high-dimensional feature spaces and large training sets. 

We demonstrate the proposed framework on three steganographic algorithms designed to hide messages in images represented in the spatial domain: HUGO, edge-adaptive algorithm by Luo , and optimally coded ternary ±1 embedding. 

For each algorithm, we apply a simple submodel-selection technique to increase the detection accuracy per model dimensionality and show how the detection saturates with increasing complexity of the rich model. 

By observing the differences between how different submodels engage in detection, an interesting interplay between the embedding and detection is revealed. 

Steganalysis built around rich image models combined with ensemble classifiers is a promising direction towards automatizing steganalysis for a wide spectrum of steganographic schemes.

```

79. Wang W, Dong J, Tan T. Exploring DCT coefficient quantization effects for local tampering detection. IEEE Trans. on Information Forensics and Security, 2014,9(10):1653−1666.

Link : https://ieeexplore.ieee.org/document/6871380

Note : 利用 JPEG 压缩分析篡改痕迹

```
In this paper, we focus on local image tampering detection. 

For a JPEG image, the probability distributions of its DCT coefficients will be disturbed by tampering operation. 

The tampered region and the unchanged region have different distributions, which is an important clue for locating tampering. 

Based on the assumption of Laplacian distribution of unquantized ac DCT coefficients, these two distributions as well as the size of tampered region can be estimated so that the probability of each DCT block being tampered is obtained. 

More accurate localization results could be got when we consider the prior knowledge of common tampered regions. 

We also design three kinds of features that can distinguish truly tampered regions from the false ones to reduce false alarm. 

For a tampered image which is saved in lossless compressed format, we also propose the specialized approach, which employs the quantization noise of high-frequency DCT coefficient, to improve the tampering localization performance. 

Extensive experiments on large scale databases prove the effectiveness of our proposed method and demonstrate that our method is suitable for locating tampered regions with different scales.
```

80. Nataraj L, Sarkar A, Manjunath BS. Adding gaussian noise to “denoise” JPEG for detecting image resizing. In: Proc. of the 16th IEEE Int’l Conf. on Image Processing (ICIP). IEEE, 2009. 1493−1496.

Link : https://ieeexplore.ieee.org/document/5414609

Note : 向 JPEG 压缩的图像中添加噪声提升检测性能

```
A common problem affecting most image resizing detection algorithms is that they are susceptible to JPEG compression. 

This is because JPEG introduces periodic artifacts, as it works on 8×8 blocks. 

We propose a novel yet counter intuitive technique to "denoise" JPEG images by adding Gaussian noise. 

We add a suitable amount of Gaussian noise to a resized and JPEG compressed image so that the periodicity due to JPEG compression is suppressed while that due to resizing is retained. 

The controlled Gaussian noise addition works better than median filtering and weighted averaging based filtering for suppressing the JPEG induced periodicity.
```

81. Bianchi T, De Rosa A, Piva A. Improved DCT coefficient analysis for forgery localization in JPEG images. In: Proc. of the IEEE Int’l Conf. on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2011. 2444−2447.

Link : https://ieeexplore.ieee.org/document/5946978

Note : 向 JPEG 压缩的图像中添加噪声提升检测性能

```
In this paper, we propose a statistical test to discriminate between original and forged regions in JPEG images, under the hypothesis that the former are doubly compressed while the latter are singly compressed. 

New probability models for the DCT coefficients of singly and doubly compressed regions are proposed, together with a reliable method for estimating the primary quantization factor in the case of double compression. 

Based on such models, the probability for each DCT block to be forged is derived. Experimental results demonstrate a better discriminating behavior with respect to previously proposed methods.
```

82. Pan X, Zhang X, Lyu S. Exposing image splicing with inconsistent local noise variances. In: Proc. of the IEEE Int’l Conf. on Computational Photography (ICCP). IEEE, 2012. 1−10.

Link : https://ieeexplore.ieee.org/document/6215223

Note : 利用局部噪音方差分析拼接痕迹

```
Image splicing is a simple and common image tampering operation, where a selected region from an image is pasted into another image with the aim to change its content. 

In this paper, based on the fact that images from different origins tend to have different amount of noise introduced by the sensors or post-processing steps, we describe an effective method to expose image splicing by detecting inconsistencies in local noise variances. 

Our method estimates local noise variances based on an observation that kurtosis values of natural images in band-pass filtered domains tend to concentrate around a constant value, and is accelerated by the use of integral image. 

We demonstrate the efficacy and robustness of our method based on several sets of forged images generated with image splicing.
```

83. Ferrara P, Bianchi T, De Rosa A, Piva A. Image forgery localization via fine-grained analysis of CFA artifacts. IEEE Trans. on Information Forensics and Security, 2012,7(5):1566−1577.

Link : https://ieeexplore.ieee.org/document/6210378

Note : 利用色彩过滤矩阵(color filter array,简称 CFA)模型进行篡改定位

```

In this paper, a forensic tool able to discriminate between original and forged regions in an image captured by a digital camera is presented. 

We make the assumption that the image is acquired using a Color Filter Array, and that tampering removes the artifacts due to the demosaicking algorithm. 

The proposed method is based on a new feature measuring the presence of demosaicking artifacts at a local level, and on a new statistical model allowing to derive the tampering probability of each 2 × 2 image block without requiring to know a priori the position of the forged region. 

Experimental results on different cameras equipped with different demosaicking algorithms demonstrate both the validity of the theoretical model and the effectiveness of our scheme.
```

84. Cozzolino D, Verdoliva L. Noiseprint: A CNN-based camera model fingerprint. IEEE Trans. on Information Forensics and Security, 2019,15:144−159.

Link : https://arxiv.org/abs/1808.08396

Note : Cozzolino 等人设计了一个孪生网络,在来自不同相机的图像块上训练来提取图片的噪音指纹,从而实现检测.

```
Forensic analyses of digital images rely heavily on the traces of in-camera and out-camera processes left on the acquired images. 

Such traces represent a sort of camera fingerprint. 

If one is able to recover them, by suppressing the high-level scene content and other disturbances, a number of forensic tasks can be easily accomplished. 

A notable example is the PRNU pattern, which can be regarded as a device fingerprint, and has received great attention in multimedia forensics. 

In this paper we propose a method to extract a camera model fingerprint, called noiseprint, where the scene content is largely suppressed and model-related artifacts are enhanced. 

This is obtained by means of a Siamese network, which is trained with pairs of image patches coming from the same (label +1) or different (label -1) cameras.

Although noiseprints can be used for a large variety of forensic tasks, here we focus on image forgery localization. 

Experiments on several datasets widespread in the forensic community show noiseprint-based methods to provide state-of-the-art performance.
```

85. Zhou P, Han X, Morariu VI, Davis LS. Learning rich features for image manipulation detection. In: Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition. 2018. 1053−1061.

Link : https://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_Learning_Rich_Features_CVPR_2018_paper.html

Note : Zhou 等人提出了基于双流的 Faster R-CNN 网络

```
Image manipulation detection is different from traditional semantic object detection because it pays more attention to tampering artifacts than to image content, which suggests that richer features need to be learned. 

We propose a two-stream Faster R-CNN network and train it end-to- end to detect the tampered regions given a manipulated image. 

One of the two streams is an RGB stream whose purpose is to extract features from the RGB image input to find tampering artifacts like strong contrast difference, unnatural tampered boundaries, and so on. 

The other is a noise stream that leverages the noise features extracted from a steganalysis rich model filter layer to discover the noise inconsistency between authentic and tampered regions. 

We then fuse features from the two streams through a bilinear pooling layer to further incorporate spatial co-occurrence of these two modalities. 

Experiments on four standard image manipulation datasets demonstrate that our two-stream framework outperforms each individual stream, and also achieves state-of-the-art performance compared to alternative methods with robustness to resizing and compression.
```

86. Rao Y, Ni J. A deep learning approach to detection of splicing and copy-move forgeries in images. In: Proc. of the IEEE Int’l Workshop on Information Forensics and Security (WIFS). IEEE, 2016. 1−6.

Link : https://ieeexplore.ieee.org/document/7823911

Note : 融合两条流的特征进行学习两个模态空间的信息.利用深度学习技术提取关键取证特征的工作也被不断探究

```
In this paper, we present a new image forgery detection method based on deep learning technique, which utilizes a convolutional neural network (CNN) to automatically learn hierarchical representations from the input RGB color images. 

The proposed CNN is specifically designed for image splicing and copy-move detection applications. 

Rather than a random strategy, the weights at the first layer of our network are initialized with the basic high-pass filter set used in calculation of residual maps in spatial rich model (SRM), which serves as a regularizer to efficiently suppress the effect of image contents and capture the subtle artifacts introduced by the tampering operations. 

The pre-trained CNN is used as patch descriptor to extract dense features from the test images, and a feature fusion technique is then explored to obtain the final discriminative features for SVM classification. 

The experimental results on several public datasets show that the proposed CNN based model outperforms some state-of-the-art methods.
```

87. Liu B, Pun CM. Deep fusion network for splicing forgery localization. In: Proc. of the European Conf. on Computer Vision (ECCV). 2018. 237−251.

Link : https://openaccess.thecvf.com/content_ECCVW_2018/papers/11130/Liu_Deep_fusion_network_for_splicing_forgery_localization_ECCVW_2018_paper.pdf

Note : Liu 等人提出一个新的深度融合网络通过追踪边界来定位篡改区域

```
Digital splicing is a common type of image forgery: some regions of an image are replaced with contents from other images. 

To locate altered regions in a tampered picture is a challenging work because the difference is unknown between the altered regions and the original regions and it is thus necessary to search the large hypothesis space for a convincing result. 

In this paper, we proposed a novel deep fusion network to locate tampered area by tracing its border. 

A group of deep convolutional neural networks called Base-Net were firstly trained to response the certain type of splicing forgery respectively. 

Then, some layers of the Base-Net are selected and combined as a deep fusion neural network (Fusion-Net). 

After fine-tuning by a very small number of pictures, Fusion-Net is able to discern whether an image block is synthesized from different origins. 

Experiments on the benchmark datasets show that our method is effective in various situations and outperform state-of-the-art methods
```

88. Huh M, Liu A, Owens A, Efros A. Fighting fake news: Image splice detection via learned self-consistency. In: Proc. of the European Conf. on Computer Vision (ECCV). 2018. 101−117.

Link : https://openaccess.thecvf.com/content_ECCV_2018/html/Jacob_Huh_Fighting_Fake_News_ECCV_2018_paper.html

Note : Minyoung 等人通过训练照片所包含的相机 EXIF 源数据指纹信息来区分图片是否被拼接

```
Advances in photo editing and manipulation tools have made it significantly easier to create fake imagery, highlighting the need for better visual forensics algorithms.

However, learning to detect manipulations from labelled training data is difficult due to the lack of good datasets of manipulated visual content. 

In this paper, we introduce a self-supervised method for learning to detect a visual manipulations using only unlabeled data. 

Given a large collection of real photographs with automatically recorded EXIF meta-data, we train a model to determine whether an image is self-consistent -- that is, whether its content could have been produced by a single imaging pipeline. We apply this self-supervised learning method to the task of localizing spliced image content. 

Our forensics model achieves state of the art results on many benchmarks, despite being trained without examples of actual manipulations, and without modeling specific detection cues. 

Beyond handcrafted benchmarks, we also show promising results spotting fakes on Reddit and The Onion, as well as detecting computer-generated splices.
```

89. Cun X, Pun CM. Image splicing localization via semi-global network and fully connected conditional random fields. In: Proc. of the European Conf. on Computer Vision (ECCV). 2018. 252−266.

Link : https://openaccess.thecvf.com/content_ECCVW_2018/papers/11130/Cun_Image_Splicing_Localization_via_Semi-Global_Network_and_Fully_Connected_Conditional_ECCVW_2018_paper.pdf

Note : Xiaodong 等人根据全局与局部块的特征不一致性学习一个半-全局网络实现拼接定位

```
We address the problem of image splicing localization: given an input image, localizing the spliced region which is cut from another image. 

We formulate this as a classification task but, critically, instead of classifying the spliced region by local patch, we leverage the features from whole image and local patch together to classify patch. 

We call this structure Semi-Global Network. 

Our approach exploits the observation that the spliced region should not only highly relate to local features (spliced edges), but also global features (semantic information, illumination, etc.) from the whole image. 

Furthermore, we first integrate Fully Connected Conditional Random Fields as post-processing technique in image splicing to improve the consistency between the input image and the output of the network. 

We show that our method outperforms other state-of-the-art methods in three popular datasets.
```

90. Cozzolino D, Poggi G, Verdoliva L. Recasting residual-based local descriptors as convolutional neural networks: An application to image forgery detection. In: Proc. of the 5th ACM Workshop on Information Hiding and Multimedia Security. 2017. 159−164.

Link : https://arxiv.org/abs/1703.04615

Note : Cozzolino 等人提出使用卷积神经网络来学习基于残差的特征,此类特征可以有效提升取证检测和定位的性能

```
Local descriptors based on the image noise residual have proven extremely effective for a number of forensic applications, like forgery detection and localization. 

Nonetheless, motivated by promising results in computer vision, the focus of the research community is now shifting on deep learning. 

In this paper we show that a class of residual-based descriptors can be actually regarded as a simple constrained convolutional neural network (CNN). 

Then, by relaxing the constraints, and fine-tuning the net on a relatively small training set, we obtain a significant performance improvement with respect to the conventional detector.
```

91. Chen C, McCloskey S, Yu J. Focus manipulation detection via photometric histogram analysis. In: Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition. 2018. 1674−1682.

Link : https://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_Focus_Manipulation_Detection_CVPR_2018_paper.pdf

Note : Chen 等人则利用神经网络学习自然模糊和人为模糊带来的光直方图不一致性

```
With the rise of misinformation spread via social media channels, enabled by the increasing automation and realism of image manipulation tools, image forensics is an increasingly relevant problem. 

Classic image forensic methods leverage low-level cues such as metadata, sensor noise fingerprints, and others that are easily fooled when the image is re-encoded upon upload to facebook, etc. 

This necessitates the use of higher-level physical and semantic cues that, once hard to estimate reliably in the wild, have become more effective due to the increasing power of computer vision. 

In particular, we detect manipulations introduced by artificial blurring of the image, which creates inconsistent photometric relationships between image intensity and various cues. 

We achieve 98% accuracy on the most challenging cases in a new dataset of blur manipulations, where the blur is geometrically correct and consistent with the scene’s
physical arrangement. 

Such manipulations are now easily generated, for instance, by smartphone cameras having hardware to measure depth, e.g. ‘Portrait Mode’ of the iPhone7Plus. 

We also demonstrate good performance on a challenge dataset evaluating a wider range of manipulations in imagery representing ‘in the wild’ conditions.
```

92. Zhou P, Han X, Morariu VI, Davis LS. Two-stream neural networks for tampered face detection. In: Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition Workshops (CVPRW). IEEE, 2017. 1831−1839.

Link : https://arxiv.org/abs/1803.11276

Note : Zhou 等人将隐写噪声特征和卷积网络学习边界特征结合,提出了一个双流神经网络的方法.具体是用一个脸分类流训练一个 GoogleNet 检测篡改的人工痕迹,利用捕捉的局部噪音特征和拍照特征训练一个基于块的三元组(triplet) 网络,用这两条流的得分,综合判断是否图像被篡改.这是因为基于同一张图像的隐藏特征是相似的,距离小;不 同图像的块之间的隐藏特征距离大,用三元组训练出块的距离编码后,用一个 SVM 分类得到概率分数. 

```
We propose a two-stream network for face tampering detection. 

We train GoogLeNet to detect tampering artifacts in a face classification stream, and train a patch based triplet network to leverage features capturing local noise residuals and camera characteristics as a second stream. 

In addition, we use two different online face swapping applications to create a new dataset that consists of 2010 tampered images, each of which contains a tampered face. 

We evaluate the proposed two-stream network on our newly collected dataset. Experimental results demonstrate the effectiveness of our method.
```

93. Szegedy C, Liu W, Jia Y, Sermanet P, Reed S, Anguelov D, Erhan D, Vanhoucke V, Rabinovich A. Going deeper with convolutions. In: Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition. 2015. 1−9.

Link : https://arxiv.org/abs/1409.4842

Note : 谷歌提出的神经网络框架 GoogLeNet

```
We propose a deep convolutional neural network architecture codenamed "Inception", which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014). 

The main hallmark of this architecture is the improved utilization of the computing resources inside the network. 

This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. 

To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. 

One particular incarnation used in our submission for ILSVRC 2014 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.
```

94. Yang X, Li Y, Lyu S. Exposing deep fakes using inconsistent head poses. In: Proc. of the IEEE Int’l Conf. on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2019. 8261−8265.

Link : https://arxiv.org/abs/1811.00661

Note : Yang 等人认为 Deepfakes 创造的是分离的合成脸区域,这样在计算 3D 头部姿态评估的时候就会引入错误.

因为 Deepfakes 是交换中心脸区域的脸,脸外围关键点的位置仍保持不变,中心和外围位置的关键点坐标不匹配,会导致 3D 头部姿态评估的不一致,故用中心区域的关键点计算一个头方向向量,整个脸计算的头方向向量,衡量这两个向量之间的差异.
针对视频计算所有帧的头部姿态差异,最后训练一个支持向量机(SVM)分类器来学习这种差异

```
In this paper, we propose a new method to expose AI-generated fake face images or videos (commonly known as the Deep Fakes). 

Our method is based on the observations that Deep Fakes are created by splicing synthesized face region into the original image, and in doing so, introducing errors that can be revealed when 3D head poses are estimated from the face images. 

We perform experiments to demonstrate this phenomenon and further develop a classification method based on this cue. 

Using features based on this cue, an SVM classifier is evaluated using a set of real face images and Deep Fakes.
```

95. Yang X, Li Y, Qi H, Lyu S. Exposing GAN-synthesized faces using landmark locations. In: Proc. of the ACM Workshop on Information Hiding and Multimedia Security. 2019. 113−118.

Link : https://arxiv.org/abs/1904.00167

Note : Yang 等人同时发现,GAN 网络生成的假人脸在关键点位置分布上与真实人脸不尽相同,尽管生成的假人脸在脸部细节上与真人相似,但是自然性和连贯性还是与真人有很大的不同之处,通过将关键点归一化的位置坐标作为特征喂入 SVM 分类器进行学习

```
Generative adversary networks (GANs) have recently led to highly realistic image synthesis results. 

In this work, we describe a new method to expose GAN-synthesized images using the locations of the facial landmark points. 

Our method is based on the observations that the facial parts configuration generated by GAN models are different from those of the real faces, due to the lack of global constraints. 

We perform experiments demonstrating this phenomenon, and show that an SVM classifier trained using the locations of facial landmark points is sufficient to achieve good classification performance for GAN-synthesized faces.
```

96. Li Y, Chang MC, Lyu S. In ictu oculi: Exposing AI created fake videos by detecting eye blinking. In: Proc. of the IEEE Int’l Workshop on Information Forensics and Security (WIFS). IEEE, 2018. 1−7.

Link : https://ieeexplore.ieee.org/document/8630787

Note : Li 等人发现,正常人的眨眼频率和时间都有一定的范围,而 Deepfakes 伪造视频的人基本没有眨眼现象,或者频率跟正常视频有较大差别,这可能是伪造视频在生成时没有丰富多样的眨眼素材导致的

```
The new developments in deep generative networks have significantly improve the quality and efficiency in generating realistically-looking fake face videos. 

In this work, we describe a new method to expose fake face videos generated with deep neural network models. 

Our method is based on detection of eye blinking in the videos, which is a physiological signal that is not well presented in the synthesized fake videos. 

Our method is evaluated over benchmarks of eye-blinking detection datasets and shows promising performance on detecting videos generated with DNN based software DeepFake.
```

97. Ciftci UA, Demir I. FakeCatcher: Detection of synthetic portrait videos using biological signals. arXiv preprint arXiv:1901.02212, 2019.

Link : https://arxiv.org/abs/1901.02212

Note : Ciftci 等人从脸部抽取 3 块区域来测量光电容积脉搏波信号,并将信号转换为一致性和连贯性特征,最后使用 SVM 对特征进行二分类

```
The recent proliferation of fake portrait videos poses direct threats on society, law, and privacy. 

Believing the fake video of a politician, distributing fake pornographic content of celebrities, fabricating impersonated fake videos as evidence in courts are just a few real world consequences of deep fakes. 

We present a novel approach to detect synthetic content in portrait videos, as a preventive solution for the emerging threat of deep fakes. 

In other words, we introduce a deep fake detector. 

We observe that detectors blindly utilizing deep learning are not effective in catching fake content, as generative models produce formidably realistic results. 

Our key assertion follows that biological signals hidden in portrait videos can be used as an implicit descriptor of authenticity, because they are neither spatially nor temporally preserved in fake content. 

To prove and exploit this assertion, we first engage several signal transformations for the pairwise separation problem, achieving 99.39% accuracy. 

Second, we utilize those findings to formulate a generalized classifier for fake content, by analyzing proposed signal transformations and corresponding feature sets.

Third, we generate novel signal maps and employ a CNN to improve our traditional classifier for detecting synthetic content. Lastly, we release an "in the wild" dataset of fake portrait videos that we collected as a part of our evaluation process. 

We evaluate FakeCatcher on several datasets, resulting with 96%, 94.65%, 91.50%, and 91.07% accuracies, on Face Forensics, Face Forensics++, CelebDF, and on our new Deep Fakes Dataset respectively. 

We also analyze signals from various facial regions, under image distortions, with varying segment durations, from different generators, against unseen datasets, and under several dimensionality reduction techniques.
```

98. Fernandes S, Raj S, Ortiz E, Vintila I, Salter M, Urosevic G, Jha S. Predicting heart rate variations of Deepfake videos using neural ODE. In: Proc. of the IEEE Int’l Conf. on Computer Vision Workshops. 2019. 1721−1729.

Link : https://ieeexplore.ieee.org/document/9022055

Note : Fernandes 等人利用心率生物信号来区分伪造视频,先通过血流造成的脸部皮肤颜色变化、前额的平均光密度、欧拉影像变化等 3 种方法来提取心率,然后采用神经常微分方程模型训练,最后测试 Deepfakes 视频时,主要依据正常视频与异常视频的心率分布不同.

```
Deepfake is a technique used to manipulate videos using computer code. 

It involves replacing the face of a person in a video with the face of another person. 

The automation of video manipulation means that deepfakes are becoming more prevalent and easier to implement. 

This can be credited to the emergence of apps like FaceApp and FakeApp, which allow users to create their own deepfake videos using their smartphones. 

It has hence become essential to detect fake videos, to avoid the spread of false information. 

A recent study shows that the heart rate of fake videos can be used to distinguish original and fake videos. 

In the study presented, we obtained the heart rate of original videos and trained the state-of-the-art Neural Ordinary Differential Equations (Neural-ODE) model. 

We then created deepfake videos using commercial software. 

The average loss obtained for ten original videos is 0.010927, and ten donor videos are 0.010041. 

The trained Neural-ODE was able to predict the heart rate of our 10 deepfake videos generated using commercial software and 320 deepfake videos of deepfakeTIMI database.

To best of our knowledge, this is the first attempt to train a Neural-ODE on original videos to predict the heart rate of fake videos.
```

99. Li Y, Lyu S. Exposing Deepfake videos by detecting face warping artifacts. In: Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) Workshops, 2019. 46−52.

Link : https://arxiv.org/abs/1811.00656

Note : Li 等人认为 Deepfakes 算法生成的图像分辨率有限,之后需要被转换到匹配替换的脸,这使得Deepfakes 的视频中留下更多可以辨别的人工痕迹,这个可以被深度神经网络有效地捕捉

```
In this work, we describe a new deep learning based method that can effectively distinguish AI-generated fake videos (referred to as {\em DeepFake} videos hereafter) from real videos. 

Our method is based on the observations that current DeepFake algorithm can only generate images of limited resolutions, which need to be further warped to match the original faces in the source video. 

Such transforms leave distinctive artifacts in the resulting DeepFake videos, and we show that they can be effectively captured by convolutional neural networks (CNNs). 

Compared to previous methods which use a large amount of real and DeepFake generated images to train CNN classifier, our method does not need DeepFake generated images as negative training examples since we target the artifacts in affine face warping as the distinctive feature to distinguish real and fake images. 

The advantages of our method are two-fold: (1) Such artifacts can be simulated directly using simple image processing operations on a image to make it as negative example.

Since training a DeepFake model to generate negative examples is time-consuming and resource-demanding, our method saves a plenty of time and resources in training data collection; (2) Since such artifacts are general existed in DeepFake videos from different sources, our method is more robust compared to others. 

Our method is evaluated on two sets of DeepFake video datasets for its effectiveness in practice.
```

100. He K, Zhang X, Ren S, Sun J. Deep residual learning for image recognition. In: Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition. 2016. 770−778. 

Link : https://arxiv.org/abs/1512.03385

Note : ResNet 

```
Deeper neural networks are more difficult to train. 

We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. 

We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. 

We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. 

On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers-8x deeper than VGG nets but still having lower complexity. 

An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. 

This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers.

The depth of representations is of central importance for many visual recognition tasks. 

Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. 

Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.
```

101. Deepfakes. 2019. https://github.com/deepfakes/faceswap

Link : https://github.com/deepfakes/faceswap

Note : Deepfakes 换脸技术


102. Zao app. 2019. https://zao-app.com/

Link : https://zao-app.com/

Note : Zao APP 提供大众换脸娱乐服务等


103. Deepfake detection challenge. 2020. https://www.kaggle.com/c/deepfake-detection-challenge

Link : https://www.kaggle.com/c/deepfake-detection-challenge

Note : Deepfakes 检测竞赛


104. Girish N, Nandini C. A review on digital video forgery detection techniques in cyber forensics. Science, Technology and Development, 2019,3(6):235−239.

Link : http://journalstd.com/gallery/28-sep2019a.pdf

Note : 只有针对早期图像篡改工作的一些总结

```
In this propelled day and age, we are abstractly developing with the mixed media content, especially digitized images and videos, to give a strong affirmation of occasion of events. 

However, less attention has been paid to the forensic video. 

Be that as it may, the availability of a couple of cutting edge ones has been created now to adjust or alter content/video altering and the product has created exceptional concern with respect to the unwavering quality of such content. 

Subsequently, over the last few years, forensic analysis of visual media has become a fundamental field of research, which essentially deals with the development of tools and systems that help decide whether advanced content under thinking is genuine or authentic, that is, a real and unaltered representation. 

Over the last few decades, this field of research has shown tremendous development and progress. 

However, existing contributions in this field are based on the manual comparison of the structure and content of the video container, which is time-consuming and
error-prone. 

The current work shows an exhaustive and exhaustive tendency to distributed writing in the field of cyber forensic investigation for the detection of video forgery, with an essential focus on the detection of forgery / manipulation, forgery of video capture and copying, and anti -forensic and enemy video counter of the crime scene investigation. 

Video Forensics continues to develop new technologies to verify the authenticity and integrity of digital videos. 
While most of the existing methods are based on the analysis of video data flow, recently, a new line of research was introduced to investigate the video life cycle based on video container analysis.
```

105. Nguyen TT, Nguyen CM, Nguyen DT, Nguyen DT, Nahavandi S. Deep learning for Deepfakes creation and detection. arXiv preprint arXiv:1909.11573, 2019.

Link : https://arxiv.org/abs/1909.11573

Note : 只有针对早期图像篡改工作的一些总结

```
Deep learning has been successfully applied to solve various complex problems ranging from big data analytics to computer vision and human-level control. 

Deep learning advances however have also been employed to create software that can cause threats to privacy, democracy and national security. 

One of those deep learning-powered applications recently emerged is deepfake. 

Deepfake algorithms can create fake images and videos that humans cannot distinguish them from authentic ones. 

The proposal of technologies that can automatically detect and assess the integrity of digital visual media is therefore indispensable. 

This paper presents a survey of algorithms used to create deepfakes and, more importantly, methods proposed to detect deepfakes in the literature to date. 

We present extensive discussions on challenges, research trends and directions related to deepfake technologies. 

By reviewing the background of deepfakes and state-of-the-art deepfake detection methods, this study provides a comprehensive overview of deepfake techniques and facilitates the development of new and more robust methods to deal with the increasingly challenging deepfakes.
```

106. Zollhöfer M, Thies J, Garrido P, Bradley D, Beeler T, Perez P, Stamminger M, Niessner M, Theobalt C. State of the art on monocular 3D face reconstruction, tracking, and applications. Computer Graphics Forum, 2018,37(2):523−550.

Link : https://studios.disneyresearch.com/wp-content/uploads/2019/03/State-of-the-Art-on-Monocular-3D-Face-Reconstruction-Tracking-and-Applications-1.pdf

Note : Zollhofer 等人综述了当前比较主流的 3D 模型重建追踪等技术

```
The computer graphics and vision communities have dedicated long standing efforts in building computerized tools for reconstructing, tracking, and analyzing human faces based on visual input. 

Over the past years rapid progress has been made, which led to novel and powerful algorithms that obtain impressive results even in the very challenging case of reconstruction from a single RGB or RGB-D camera. 

The range of applications is vast and steadily growing as these technologies are further improving in speed, accuracy, and ease of use.

Motivated by this rapid progress, this state-of-the-art report summarizes recent trends in monocular facial performance capture and discusses its applications, which range from performance-based animation to real-time facial reenactment. 

We focus our discussion on methods where the central task is to recover and track a three dimensional model of the human face using optimization-based reconstruction algorithms. 

We provide an in-depth overview of the underlying concepts of real-world image formation, and we discuss common assumptions and simplifications that make these algorithms practical. 

In addition, we extensively cover the priors that are used to better constrain the under-constrained monocular reconstruction problem, and discuss the optimization techniques that are employed to recover dense, photo-geometric 3D face models from monocular 2D data. 

Finally, we discuss a variety of use cases for the reviewed algorithms in the context of motion capture, facial animation, as well as image and video editing.
```

107. FaceSwap. 2019. https://github.com/MarekKowalski/FaceSwap/

Link : https://github.com/MarekKowalski/FaceSwap/

Note : FaceSwap 是基于图形学的换脸方法,首先获取人脸关键点,然后通过 3D 模型对获取到的人脸关键点位置进行渲染,不断缩小目标形状和关键点定位间的差异,最后将渲染模型的图像进行混合,并利用色彩校正技术获取最终的图像


108. Dale K, Sunkavalli K, Johnson MK, Vlasic D, Matusik W, Pfister H. Video face replacement. In: Proc. of the SIGGRAPH Asia Conf. 2011. 1−10.

Link : https://vcg.seas.harvard.edu/publications/video-face-replacement

Note : Kevin 等提出了在视频里自动换脸的 3D 方法,不需要大量的手动操作和硬件采集,只需要一个单相机视频,通过用 3D 多线性模型追踪视频中的人脸,并用相应的 3D 形状将源人脸仿射到目标人脸

```
We present a method for replacing facial performances in video. 

Our approach accounts for differences in identity, visual appearance, speech, and timing between source and target videos. 

Unlike prior work, it does not require substantial manual operation or complex acquisition hardware, only single-camera video. 

We use a 3D multilinear model to track the facial performance in both videos. 

Using the corresponding 3D geometry, we warp the source to the target face and retime the source to match the target performance. 

We then compute an optimal seam through the video volume that maintains temporal consistency in the final composite. 

We showcase the use of our method on a variety of examples and present the result of a user study that suggests our results are difficult to distinguish from real video footage.
```

109. Garrido P, Valgaerts L, Rehmsen O, Thormae T, Perez P, Theobalt C. Automatic face reenactment. In: Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition. 2014. 4217−4224.

Link : https://vcai.mpi-inf.mpg.de/projects/FaceReenactment/files/FaceReenactment.pdf

Note : Pablo 等人用类似的3D方法来替换目标视频中演员的人脸,而保留原始的表情

```
We propose an image-based, facial reenactment system that replaces the face of an actor in an existing target video with the face of a user from a source video, while preserving the original target performance. 

Our system is fully automatic and does not require a database of source expressions.

Instead, it is able to produce convincing reenactment results from a short source video captured with an off-theshelf camera, such as a webcam, where the user performs
arbitrary facial gestures. 

Our reenactment pipeline is conceived as part image retrieval and part face transfer: 

The image retrieval is based on temporal clustering of target frames and a novel image matching metric that combines appearance and motion to select candidate frames from the source video, while the face transfer uses a 2D warping strategy that preserves the user’s identity. 

Our system excels in simplicity as it does not rely on a 3D face model, it is robust under head motion and does not require the source and target performance to be similar. 

We show convincing reenactment results for videos that we recorded ourselves and for low-quality footage taken from the Internet.
```

110. Garrido P, Valgaerts L, Sarmadi H, Steiner I, Varanasi K, Perez P, Theobalt C. VDub: Modifying face video of actors for plausible visual alignment to a dubbed audio track. Computer Graphics Forum, 2015,34(2):193−204.

Link : https://vcai.mpi-inf.mpg.de/files/EuroGraphics2015/dubbing_high.pdf

Note : Pablo等人设计了一个系统,通过高质量的 3D 人脸捕捉技术,改变人脸从而匹配嘴巴的动作

```
In many countries, foreign movies and TV productions are dubbed, i.e., the original voice of an actor is replaced with a translation that is spoken by a dubbing actor in the country’s own language. 

Dubbing is a complex process that requires specific translations and accurately timed recitations such that the new audio at least coarsely adheres to the mouth motion in the video. 

However, since the sequence of phonemes and visemes in the original and the dubbing language are different, the video-to-audio match is never perfect, which is a major source of visual discomfort. 

In this paper, we propose a system to alter the mouth motion of an actor in a video, so that it matches the new audio track. 

Our paper builds on high-quality monocular capture of 3D facial performance, lighting and albedo of the dubbing and target actors, and uses audio analysis in combination with a space-time retrieval method to synthesize a new photo-realistically rendered and highly detailed 3D shape model of the mouth region to replace the target performance. 

We demonstrate plausible visual quality of our results compared to footage that has been professionally dubbed in the traditional way, both qualitatively and through a user study.
```

111. Nirkin Y, Masi I, Tuan AT, Hassner T, Medioni G. On face segmentation, face swapping, and face perception. In: Proc. of the 13th IEEE Int’l Conf. on Automatic Face and Gesture Recognition (FG 2018). IEEE, 2018. 98−105.

Link : https://arxiv.org/abs/1704.06729

Note : Nirkin 等人用分割的思路促进换脸,通过网络分割出来的人脸估计 3D 人脸形状,最后融合源和目标这两个对齐的 3D 人脸形状

```
We show that even when face images are unconstrained and arbitrarily paired, face swapping between them is actually quite simple. 

To this end, we make the following contributions. 

(a) Instead of tailoring systems for face segmentation, as others previously proposed, we show that a standard fully convolutional network (FCN) can achieve remarkably fast and accurate segmentations, provided that it is trained on a rich enough example set. 

For this purpose, we describe novel data collection and generation routines which provide challenging segmented face examples. 

(b) We use our segmentations to enable robust face swapping under unprecedented conditions. 

(c) Unlike previous work, our swapping is robust enough to allow for extensive quantitative tests. 

To this end, we use the Labeled Faces in the Wild (LFW) benchmark and measure the effect of intra- and inter-subject face swapping on recognition. 

We show that our intra-subject swapped faces remain as recognizable as their sources, testifying to the effectiveness of our method. In line with well known perceptual studies, we show that better face swapping produces less recognizable inter-subject results. This is the first time this effect was quantitatively demonstrated for machine vision systems.
```

112. Lu Z, Li Z, Cao J, He R, Sun Z. Recent progress of face image synthesis. In: Proc. of the 4th IAPR Asian Conf. on Pattern Recognition (ACPR). IEEE, 2017. 7−12.

Link : https://arxiv.org/abs/1706.04717

Note : 深度学习在人脸篡改上的应用

```
Face synthesis has been a fascinating yet challenging problem in computer vision and machine learning. 

Its main research effort is to design algorithms to generate photo-realistic face images via given semantic domain. 

It has been a crucial prepossessing step of main-stream face recognition approaches and an excellent test of AI ability to use complicated probability distributions. 

In this paper, we provide a comprehensive review of typical face synthesis works that involve traditional methods as well as advanced deep learning approaches. 

Particularly, Generative Adversarial Net (GAN) is highlighted to generate photo-realistic and identity preserving results. 

Furthermore, the public available databases and evaluation metrics are introduced in details. 

We end the review with discussing unsolved difficulties and promising directions for future research.
```

113. Goodfellow I, Pouget-Abadie J, Mirza M, Xu B, Warde-Farley D, Ozair S, Courvile A, Bengio Y. Generative adversarial nets. In: Proc. of the Advances in Neural Information Processing Systems. 2014. 2672−2680.

Link : https://arxiv.org/abs/1406.2661

Note : GAN

```
We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: 

a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. 

The training procedure for G is to maximize the probability of D making a mistake. 

This framework corresponds to a minimax two-player game. 

In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. 

In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. 

There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. 

Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.
```

114. Faceswap-GAN. 2019. https://github.com/shaoanlu/faceswap-GAN

Link : https://github.com/shaoanlu/faceswap-GAN

Note : Faceswap-GAN 就是增加了 GAN 技术的 Deepfakes,引入判别器的对抗损失函数,在生成的时候判别生成图像和原图的相似度,使得生成的图像质量有大幅度提高,另外引入了感知损失函数增加眼珠的转动效果


115. Korshunova I, Shi W, Dambre J, Theis L. Fast face-swap using convolutional neural networks. In: Proc. of the IEEE Int’l Conf. on Computer Vision. 2017. 3677−3685.

Link : https://arxiv.org/abs/1611.09577

Note : Korshunova 等人将换脸问题视为风格迁移问题,训练一个卷积神经网络,从非结构化的图片中学习这种外观,并设计内容损失和风格损失函数来保障生成高质量真实度的人脸图像.这些人脸转换还是依赖于大量的
源和目标人物的人脸图片训练,泛化性不强

```
We consider the problem of face swapping in images, where an input identity is transformed into a target identity while preserving pose, facial expression, and lighting. 

To perform this mapping, we use convolutional neural networks trained to capture the appearance of the target identity from an unstructured collection of his/her photographs.

This approach is enabled by framing the face swapping problem in terms of style transfer, where the goal is to render an image in the style of another one. 

Building on recent advances in this area, we devise a new loss function that enables the network to produce highly photorealistic results. 

By combining neural networks with simple pre- and post-processing steps, we aim at making face swap work in real-time with no input from the user.
```

116. Nirkin Y, Keller Y, Hassner T. FSGAN: Subject agnostic face swapping and reenactment. In: Proc. of the IEEE Int’l Conf. on Computer Vision. 2019. 7184−7193.

Link : https://arxiv.org/abs/1908.05932

Note : Yuval 等人基于 GAN 技术提出了一个主体无关的人脸替换和重建方法,通过引入特定域感知损失、重建损失和对抗损失,可以应用于成对的人脸,不需要在大量人脸上训练

```
We present Face Swapping GAN (FSGAN) for face swapping and reenactment. 

Unlike previous work, FSGAN is subject agnostic and can be applied to pairs of faces without requiring training on those faces. 

To this end, we describe a number of technical contributions. 

We derive a novel recurrent neural network (RNN)-based approach for face reenactment which adjusts for both pose and expression variations and can be applied to a single image or a video sequence. 

For video sequences, we introduce continuous interpolation of the face views based on reenactment, Delaunay Triangulation, and barycentric coordinates. 

Occluded face regions are handled by a face completion network. 

Finally, we use a face blending network for seamless blending of the two faces while preserving target skin color and lighting conditions. 

This network uses a novel Poisson blending loss which combines Poisson optimization with perceptual loss. We compare our approach to existing state-of-the-art systems and show our results to be both qualitatively and quantitatively superior.
```

117. Choi Y, Choi M, Kim M, Ha J, Kin S, Choo J. StarGAN: Unified generative adversarial networks for multi-domain image-toimage translation. In: Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition. 2018. 8789−8797.

Link : https://arxiv.org/abs/1711.09020

Note : 技术被广泛用于生产虚拟的人脸和篡改人脸属性.如 StarGAN

```
Recent studies have shown remarkable success in image-to-image translation for two domains. 

However, existing approaches have limited scalability and robustness in handling more than two domains, since different models should be built independently for every pair of image domains. 

To address this limitation, we propose StarGAN, a novel and scalable approach that can perform image-to-image translations for multiple domains using only a single model.

Such a unified model architecture of StarGAN allows simultaneous training of multiple datasets with different domains within a single network. 

This leads to StarGAN's superior quality of translated images compared to existing models as well as the novel capability of flexibly translating an input image to any desired target domain. 

We empirically demonstrate the effectiveness of our approach on a facial attribute transfer and a facial expression synthesis tasks.
```

118. Zhang H, Xu T, Li H, Zhang S, Wang X, Huang X, Netaxas D. StackGAN++: Realistic image synthesis with stacked generative adversarial networks. IEEE Trans. on Pattern Analysis and Machine Intelligence, 2018,41(8):1947−1962.

Link : https://www.researchgate.net/publication/320727533_StackGAN_Realistic_Image_Synthesis_with_Stacked_Generative_Adversarial_Networks

Note : 技术被广泛用于生产虚拟的人脸和篡改人脸属性,Stackgan

```
Although Generative Adversarial Networks (GANs) have shown remarkable success in various tasks, they still face challenges in generating high quality images. 

In this paper, we propose Stacked Generative Adversarial Networks (StackGAN) aimed at generating high-resolution photorealistic images. 

First, we propose a two-stage generative adversarial network architecture, StackGAN-v1, for text-to-image synthesis. 

The Stage-I GAN sketches primitive shape and colors of the object based on given text description, yielding low-resolution images. 

The Stage-II GAN takes Stage-I results and text descriptions as inputs, and generates high-resolution images with photo-realistic details. 

Second, an advanced multi-stage generative adversarial network architecture, StackGAN-v2, is proposed for both conditional and unconditional generative tasks. 

Our StackGAN-v2 consists of multiple generators and discriminators in a tree-like structure; images at multiple scales corresponding to the same scene are generated from different branches of the tree. 

StackGAN-v2 shows more stable training behavior than StackGAN-v1 by jointly approximating multiple distributions. 

Extensive experiments demonstrate that the proposed stacked generative adversarial networks significantly outperform other state-of-the-art methods in generating photo-realistic images.
```

119. Karras T, Aila T, Laine S, Lehtinen J. Progressive growing of GANs for improved quality, stability, and variation. In: Proc. of the 6th Int’l Conf. on Learning Representations (ICLR). 2018.

Link : https://arxiv.org/abs/1710.10196

Note : 技术被广泛用于生产虚拟的人脸和篡改人脸属性,PGAN

```
We describe a new training methodology for generative adversarial networks. 

The key idea is to grow both the generator and discriminator progressively: 

starting from a low resolution, we add new layers that model increasingly fine details as training progresses. 

This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024^2. 

We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. 

Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. 

Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. 

As an additional contribution, we construct a higher-quality version of the CelebA dataset.
```

120. Antipov G, Baccouche M, Dugelay JL. Face aging with conditional generative adversarial networks. In: Proc. of the IEEE Int’l Conf. on Image Processing (ICIP). IEEE, 2017. 2089−2093.

Link : https://arxiv.org/abs/1702.01983

Note : Grigory 等人利用 conditional-GAN技术改变人的年龄

```
It has been recently shown that Generative Adversarial Networks (GANs) can produce synthetic images of exceptional visual fidelity. 

In this work, we propose the GAN-based method for automatic face aging. 

Contrary to previous works employing GANs for altering of facial attributes, we make a particular emphasize on preserving the original person's identity in the aged version of his/her face. 

To this end, we introduce a novel approach for "Identity-Preserving" optimization of GAN's latent vectors. 

The objective evaluation of the resulting aged and rejuvenated face images by the state-of-the-art face recognition and age estimation solutions demonstrate the high potential of the proposed method.
```

121. Mirza M, Osindero S. Conditional generative adversarial nets. arXiv preprint arXiv:1411.1784, 2014.

Link : https://arxiv.org/abs/1411.1784

Note : conditional-GAN

```
Generative Adversarial Nets were recently introduced as a novel way to train generative models. 

In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. 

We show that this model can generate MNIST digits conditioned on class labels. 

We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.
```

122. Huang R, Zhang S, Li T, He R. Beyond face rotation: Global and local perception GAN for photorealistic and identity preserving frontal view synthesis. In: Proc. of the IEEE Int’l Conf. on Computer Vision. 2017. 2439−2448.

Link : https://arxiv.org/abs/1704.04086

Note : 用 GAN 生成不同的人脸视角而保持全局的结构和局部细节

```
Photorealistic frontal view synthesis from a single face image has a wide range of applications in the field of face recognition. 

Although data-driven deep learning methods have been proposed to address this problem by seeking solutions from ample face data, this problem is still challenging because it is intrinsically ill-posed. 

This paper proposes a Two-Pathway Generative Adversarial Network (TP-GAN) for photorealistic frontal view synthesis by simultaneously perceiving global structures and local details. 

Four landmark located patch networks are proposed to attend to local textures in addition to the commonly used global encoder-decoder network. 

Except for the novel architecture, we make this ill-posed problem well constrained by introducing a combination of adversarial loss, symmetry loss and identity preserving loss. 

The combined loss function leverages both frontal face distribution and pre-trained discriminative deep face models to guide an identity preserving inference of frontal views from profiles. 

Different from previous deep learning methods that mainly rely on intermediate features for recognition, our method directly leverages the synthesized identity preserving image for downstream tasks like face recognition and attribution estimation. 

Experimental results demonstrate that our method not only presents compelling perceptual results but also outperforms state-of-the-art results on large pose face recognition.
```

123. Thies J, Zollhöfer M, Nießner M, Valgaerts L, Stamminger M, Theobalt C. Real-time expression transfer for facial reenactment. ACM Trans. on Graphics (TOG), 2015,34(6):Article No.183.

Link : http://www.graphics.stanford.edu/~niessner/papers/2015/10face/thies2015realtime.pdf

Note : Thies 等人基于一个消费级的 RGB-D 相机,重建、追踪源和目标演员的 3D 模型并最后融合,从而进行实时的表情迁移

```
We present a method for the real-time transfer of facial expressions from an actor in a source video to an actor in a target video, thus enabling the ad-hoc control of the facial expressions of the target actor. 

The novelty of our approach lies in the transfer and photorealistic re-rendering of facial deformations and detail into the target video in a way that the newly-synthesized expressions are virtually indistinguishable from a real video. 

To achieve this, we accurately capture the facial performances of the source and target subjects in real-time using a commodity RGB-D sensor. 

For each frame, we jointly fit a parametric model for identity, expression, and skin reflectance to the input color and depth data, and also reconstruct the scene lighting. 

For expression transfer, we compute the difference between the source and target expressions in parameter space, and modify the target parameters to match the source expressions. 

A major challenge is the convincing re-rendering of the synthesized target face into the corresponding video stream. 

This requires a careful consideration of the lighting and shading design, which both must correspond to the real-world environment. 

We demonstrate our method in a live setup, where we modify a video conference feed such that the facial expressions of a different person (e.g., translator) are matched in real-time.
```

124. Thies J, Zollhofer M, Stamminger M, Theobalt C, Niebner M. Face2face: Real-time face capture and reenactment of RGB videos. In: Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition. 2016. 2387−2395.

Link : https://arxiv.org/abs/2007.14808

Note : Thies 等人提出了 Face2Face,通过利用 3D 重建技术和图像渲染技术,能够在商业视频流中进行人脸移动表情的修改

```
We present Face2Face, a novel approach for real-time facial reenactment of a monocular target video sequence (e.g., Youtube video). 

The source sequence is also a monocular video stream, captured live with a commodity webcam. 

Our goal is to animate the facial expressions of the target video by a source actor and re-render the manipulated output video in a photo-realistic fashion. 

To this end, we first address the under-constrained problem of facial identity recovery from monocular video by non-rigid model-based bundling. 

At run time, we track facial expressions of both source and target video using a dense photometric consistency measure. 

Reenactment is then achieved by fast and efficient deformation transfer between source and target. 

The mouth interior that best matches the re-targeted expression is retrieved from the target sequence and warped to produce an accurate fit. 

Finally, we convincingly re-render the synthesized target face on top of the corresponding video stream such that it seamlessly blends with the real-world illumination. 

We demonstrate our method in a live setup, where Youtube videos are reenacted in real time.
```

125. Thies J, Zollhöfer M, Theobalt C, Stamminger M, Niessner M. Headon: Real-time reenactment of human portrait videos. ACM Trans. on Graphics (TOG), 2018,37(4):1−13.

Link : https://arxiv.org/pdf/1805.11729.pdf

Note : Head on 通过修改视角和姿态独立的纹理实现视频级的渲染方法,从而实现完整的人重建方法,包括表情眼睛、头部移动等

```
We propose HeadOn, the first real-time source-to-target reenactment approach for complete human portrait videos that enables transfer of torso and head motion, face expression, and eye gaze. 

Given a short RGB-D video of the target actor, we automatically construct a personalized geometry proxy that embeds a parametric head, eye, and kinematic torso model. 

A novel realtime reenactment algorithm employs this proxy to photo-realistically map the captured motion from the source actor to the target actor. 

On top of the coarse geometric proxy, we propose a video-based rendering technique that composites the modified target portrait video via view- and pose-dependent texturing, and creates photo-realistic imagery of the target actor under novel torso and head poses, facial expressions, and gaze directions. 

To this end, we propose a robust tracking of the face and torso of the source actor. 

We extensively evaluate our approach and show significant improvements in enabling much greater flexibility in creating realistic reenacted output videos.
```

126. Kim H, Garrido P, Tewari A, Xu W, Thies J, Niessner M, Perez P, Richardt C, Zollhofer M, Theobalt C. Deep video portraits. ACM Trans. on Graphics (TOG), 2018,37(4):1−14.

Link : https://gvv.mpi-inf.mpg.de/projects/DeepVideoPortraits/

Note : Kim 等人利用含有时空架构的生成网络将合成的渲染图转换成真实图,并能迁移头部表情等动作.尽管现有的图形学方法可以较好地合成或重建图像,但是严重依赖于高质量的 3D 内容

```
We present a novel approach that enables photo-realistic re-animation of portrait videos using only an input video. 

In contrast to existing approaches that are restricted to manipulations of facial expressions only, we are the first to transfer the full 3D head position, head rotation, face expression, eye gaze, and eye blinking from a source actor to a portrait video of a target actor. 

The core of our approach is a generative neural network with a novel space-time architecture. 

The network takes as input synthetic renderings of a parametric face model, based on which it predicts photo-realistic video frames for a given target actor. 

The realism in this rendering-to-video transfer is achieved by careful adversarial training, and as a result, we can create modified target videos that mimic the behavior of the synthetically-created input. 

In order to enable source-to-target video re-animation, we render a synthetic target video with the reconstructed head animation parameters from a source video, and feed it into the trained network - thus taking full control of the target. 

With the ability to freely recombine source and target parameters, we are able to demonstrate a large variety of video rewrite applications without explicitly modeling hair, body or background. 

For instance, we can reenact the full head using interactive user-controlled editing, and realize high-fidelity visual dubbing. 

To demonstrate the high quality of our output, we conduct an extensive series of experiments and evaluations, where for instance a user study shows that our video edits are hard to detect.
```

127. Thies J, Zollhöfer M, Nießner M. Deferred neural rendering: Image synthesis using neural textures. ACM Trans. on Graphics (TOG), 2019,38(4):1−12.

Link : https://arxiv.org/abs/1904.12356

Note : Thies 等人提出了延迟神经渲染的框架,与渲染网络一起优化神经纹理而生成合成的图像,此方法可以在不完美的3D内容上操作

```
The modern computer graphics pipeline can synthesize images at remarkable visual quality; 

however, it requires well-defined, high-quality 3D content as input. In this work, we explore the use of imperfect 3D content, for instance, obtained from photo-metric reconstructions with noisy and incomplete surface geometry, while still aiming to produce photo-realistic (re-)renderings. 

To address this challenging problem, we introduce Deferred Neural Rendering, a new paradigm for image synthesis that combines the traditional graphics pipeline with learnable components. 

Specifically, we propose Neural Textures, which are learned feature maps that are trained as part of the scene capture process. 

Similar to traditional textures, neural textures are stored as maps on top of 3D mesh proxies; 

however, the high-dimensional feature maps contain significantly more information, which can be interpreted by our new deferred neural rendering pipeline. 

Both neural textures and deferred neural renderer are trained end-to-end, enabling us to synthesize photo-realistic images even when the original 3D content was imperfect. 

In contrast to traditional, black-box 2D generative neural networks, our 3D representation gives us explicit control over the generated output, and allows for a wide range of application domains. 

For instance, we can synthesize temporally-consistent video re-renderings of recorded 3D scenes as our representation is inherently embedded in 3D space. 

This way, neural textures can be utilized to coherently re-render or manipulate existing video content in both static and dynamic environments at real-time rates. 

We show the effectiveness of our approach in several experiments on novel view synthesis, scene editing, and facial reenactment, and compare to state-of-the-art approaches that leverage the standard graphics pipeline as well as conventional generative neural networks.
```

128. Suwajanakorn S, Seitz SM, Kemelmacher-Shlizerman I. Synthesizing Obama: Learning lip sync from audio. ACM Trans. on Graphics (TOG), 2017,36(4):1−13.

Link : https://grail.cs.washington.edu/projects/AudioToObama/

Note : Suwajanakorn等人利用循环神经网络建立语音到嘴型动作的映射,可以匹配输入的语音合成嘴型指定纹理动作

```
Given audio of President Barack Obama, we synthesize a high quality video of him speaking with accurate lip sync, composited into a target video clip. 

Trained on many hours of his weekly address footage, a recurrent neural network learns the mapping from raw audio features to mouth shapes. 

Given the mouth shape at each time instant, we synthesize high quality mouth texture, and composite it with proper 3D pose matching to change what he appears to be saying in a target video to match the input audio track. 

Our approach produces photorealistic results.
```

129. Zakharov E, Shysheya A, Burkov E, Lempitsky V. Few-shot adversarial learning of realistic neural talking head models. In: Proc. of the IEEE Int’l Conf. on Computer Vision. 2019. 9459−9468.

Link : https://arxiv.org/abs/1905.08233

Note : 有针对人物特写镜头中的图像合成

```
Several recent works have shown how highly realistic human head images can be obtained by training convolutional neural networks to generate them. 

In order to create a personalized talking head model, these works require training on a large dataset of images of a single person. 

However, in many practical scenarios, such personalized talking head models need to be learned from a few image views of a person, potentially even a single image. 

Here, we present a system with such few-shot capability. It performs lengthy meta-learning on a large dataset of videos, and after that is able to frame few- and one-shot learning of neural talking head models of previously unseen people as adversarial training problems with high capacity generators and discriminators. 

Crucially, the system is able to initialize the parameters of both the generator and the discriminator in a person-specific way, so that training can be based on just a few images and done quickly, despite the need to tune tens of millions of parameters. 

We show that such an approach is able to learn highly realistic and personalized talking head models of new people and even portrait paintings.
```

130. Fried O, Tewari A, Zollhöfer M, Finkelstein A, Shechtman E, Goldman D, Genova K, Jin Z, Theobalt C, Agrawala M. Text-based editing of talking-head video. ACM Trans. on Graphics (TOG), 2019,38(4):1−14.

Link : https://arxiv.org/abs/1906.01524

Note : 有针对人物特写镜头中的图像合成

```
Editing talking-head video to change the speech content or to remove filler words is challenging. 

We propose a novel method to edit talking-head video based on its transcript to produce a realistic output video in which the dialogue of the speaker has been modified, while maintaining a seamless audio-visual flow (i.e. no jump cuts). 

Our method automatically annotates an input talking-head video with phonemes, visemes, 3D face pose and geometry, reflectance, expression and scene illumination per frame.

To edit a video, the user has to only edit the transcript, and an optimization strategy then chooses segments of the input corpus as base material. 

The annotated parameters corresponding to the selected segments are seamlessly stitched together and used to produce an intermediate video representation in which the lower half of the face is rendered with a parametric face model. 

Finally, a recurrent video generation network transforms this representation to a photorealistic video that matches the edited transcript. 

We demonstrate a large variety of edits, such as the addition, removal, and alteration of words, as well as convincing language translation and full sentence synthesis.
```

131. Averbuch-Elor H, Cohen-Or D, Kopf J, Cohen M. Bringing portraits to life. ACM Trans. on Graphics (TOG), 2017,36(6):Article No.196.

Link : https://dl.acm.org/doi/abs/10.1145/3130800.3130818

Note : 基于 2D 仿射的源演员表情匹配

```
We present a technique to automatically animate a still portrait, making it possible for the subject in the photo to come to life and express various emotions. 

We use a driving video (of a different subject) and develop means to transfer the expressiveness of the subject in the driving video to the target portrait. 

In contrast to previous work that requires an input video of the target face to reenact a facial performance, our technique uses only a single target image. 

We animate the target image through 2D warps that imitate the facial transformations in the driving video. 

As warps alone do not carry the full expressiveness of the face, we add fine-scale dynamic details which are commonly associated with facial expressions such as creases and wrinkles. 

Furthermore, we hallucinate regions that are hidden in the input target face, most notably in the inner mouth. 

Our technique gives rise to reactive profiles, where people in still images can automatically interact with their viewers. 

We demonstrate our technique operating on numerous still portraits from the internet.
```

132. Lample G, Zeghidour N, Usunier N, Bordes A, Denoyer L, Ranzato M. Fader networks: Manipulating images by sliding attributes. In: Proc. of the Advances in Neural Information Processing Systems. 2017. 5967−5976. 

Link : https://arxiv.org/abs/1706.00409

Note : 基于网络编码空间的属性修改的表情迁移

```
This paper introduces a new encoder-decoder architecture that is trained to reconstruct images by disentangling the salient information of the image and the values of attributes directly in the latent space. 

As a result, after training, our model can generate different realistic versions of an input image by varying the attribute values. 

By using continuous attribute values, we can choose how much a specific attribute is perceivable in the generated image. 

This property could allow for applications where users can modify an image using sliding knobs, like faders on a mixing console, to change the facial expression of a portrait, or to update the color of some objects. 

Compared to the state-of-the-art which mostly relies on training adversarial networks in pixel space by altering attribute values at train time, our approach results in much simpler training schemes and nicely scales to multiple attributes. 

We present evidence that our model can significantly change the perceived value of the attributes while preserving the naturalness of images.
```

133. Van Den Oord A, Dieleman S, Zen H, Simonyan K, Vinyals O, Graves A, Kalchbrenner N, Senior AW, Kavukcuoglu K. Wavenet: A generative model for raw audio. In: Proc. of the 9th Speech Synthesis Workshop. 2016.

Link : https://arxiv.org/abs/1609.03499

Note : WaveNet ,这是第一个端到端的语音合成器,一种基于音频生成模型,能够产生于人相似的音频

```
This paper introduces WaveNet, a deep neural network for generating raw audio waveforms. 

The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; 

nonetheless we show that it can be efficiently trained on data with tens of thousands of samples per second of audio. 

When applied to text-to-speech, it yields state-of-the-art performance, with human listeners rating it as significantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. 

A single WaveNet can capture the characteristics of many different speakers with equal fidelity, and can switch between them by conditioning on the speaker identity. 

When trained to model music, we find that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition.
```

134. Arik S, Chrzanowski M, Coates A, Diamos G, Kang Y, Li X, Miller J, Ng A, Raiman J, Sengupta S, Shoeybi M. Deep voice: Real-time neural text-to-speech. In: Proc. of the 34th Int’l Conf. on Machine Learning. 2017. 195−204.

Link : https://arxiv.org/abs/1702.07825

Note : 文本到语音合成系统 Deep voice

```
We present Deep Voice, a production-quality text-to-speech system constructed entirely from deep neural networks. 

Deep Voice lays the groundwork for truly end-to-end neural speech synthesis. 

The system comprises five major building blocks: a segmentation model for locating phoneme boundaries, a grapheme-to-phoneme conversion model, a phoneme duration prediction model, a fundamental frequency prediction model, and an audio synthesis model. 

For the segmentation model, we propose a novel way of performing phoneme boundary detection with deep neural networks using connectionist temporal classification (CTC) loss. 

For the audio synthesis model, we implement a variant of WaveNet that requires fewer parameters and trains faster than the original. 

By using a neural network for each component, our system is simpler and more flexible than traditional text-to-speech systems, where each component requires laborious feature engineering and extensive domain expertise. 

Finally, we show that inference with our system can be performed faster than real time and describe optimized WaveNet inference kernels on both CPU and GPU that achieve up to 400x speedups over existing implementations.
```

135. Wang Y, Skerry-Ryan RJ, Stanton D, Wu Y, Weiss R, Jaitly N, Yang Z, Xiao Y, Chen Z, Bengio S, Le Q, Agiomyrgiannakis Y, Clark B, Saurous R. Tacotron: Towards end-to-end speech synthesis. In: Proc. of the Interspeech 2017, 18th Annual Conf. of the Int’l Speech Communication Association. 2017. 4006−4010.

Link : https://arxiv.org/abs/1703.10135

Note : 文本到语音合成系统 Tacotron

```
A text-to-speech synthesis system typically consists of multiple stages, such as a text analysis frontend, an acoustic model and an audio synthesis module. 

Building these components often requires extensive domain expertise and may contain brittle design choices. 

In this paper, we present Tacotron, an end-to-end generative text-to-speech model that synthesizes speech directly from characters. 

Given <text, audio> pairs, the model can be trained completely from scratch with random initialization. We present several key techniques to make the sequence-to-sequence framework perform well for this challenging task. 

Tacotron achieves a 3.82 subjective 5-scale mean opinion score on US English, outperforming a production parametric system in terms of naturalness. 

In addition, since Tacotron generates speech at the frame level, it's substantially faster than sample-level autoregressive methods.
```

136. Arik S, Diamos G, Gibiansky A, Miller J, Peng K, Ping W, Raiman J, Zhou Y. Deep voice 2: Multi-speaker neural text-to-speech. In: Proc. of the Advances in Neural Information Processing Systems. 2017. 2962−2970.

Link : https://arxiv.org/abs/1705.08947

Note : 百度对 Deep voice 进行了扩展,提出了 Deep voice2,通过使用低维度可训练的说话者编码来增强文本到语音的转换,使得单个模型能生成不同的声音

```
We introduce a technique for augmenting neural text-to-speech (TTS) with lowdimensional trainable speaker embeddings to generate different voices from a single model. 

As a starting point, we show improvements over the two state-ofthe-art approaches for single-speaker neural TTS: 

Deep Voice 1 and Tacotron. We introduce Deep Voice 2, which is based on a similar pipeline with Deep Voice 1, but constructed with higher performance building blocks and demonstrates a significant audio quality improvement over Deep Voice 1. 

We improve Tacotron by introducing a post-processing neural vocoder, and demonstrate a significant audio quality improvement. 

We then demonstrate our technique for multi-speaker speech synthesis for both Deep Voice 2 and Tacotron on two multi-speaker TTS datasets. We show that a single neural TTS system can learn hundreds of unique voices from less than half an hour of data per speaker, while achieving high audio quality synthesis and preserving the speaker identities almost perfectly.
```

137. Ping W, Peng K, Gibiansky A, Arik S, Kannan A, Narang S. Deep voice 3: 2000-speaker neural text-to-speech. In: Proc. of the ICLR. 2018. 214−217.

Link : https://arxiv.org/abs/1710.07654

Note : Ping 等人提出的 Deep voice3[37]进一步改进了之前的 Deep voice 系列,Deep voice3 是一个基于注意力机制的全卷积 TTS 系统,通过设计字符到频谱图的结构,能够实现完全并行的计算,在不降低合成性能的情况下,速度更加快

```
We present Deep Voice 3, a fully-convolutional attention-based neural text-to-speech (TTS) system. 

Deep Voice 3 matches state-of-the-art neural speech synthesis systems in naturalness while training ten times faster. We scale Deep Voice 3 to data set sizes unprecedented for TTS, training on more than eight hundred hours of audio from over two thousand speakers. 

In addition, we identify common error modes of attention-based speech synthesis networks, demonstrate how to mitigate them, and compare several different waveform synthesis methods. 

We also describe how to scale inference to ten million queries per day on one single-GPU server.
```

138. Pascual S, Bonafonte A, Serra J. SEGAN: Speech enhancement generative adversarial network. In: Proc. of the Interspeech 2017, 18th Annual Conf. of the Int’l Speech Communication Association. 2017. 3642−3646.

Link : https://arxiv.org/abs/1703.09452

Note : Santiago 等人则利用 GAN 技术对语音的噪音进行过滤,提高了生成语音的质量

```
Current speech enhancement techniques operate on the spectral domain and/or exploit some higher-level feature. 

The majority of them tackle a limited number of noise conditions and rely on first-order statistics. 

To circumvent these issues, deep networks are being increasingly used, thanks to their ability to learn complex functions from large example sets. 

In this work, we propose the use of generative adversarial networks for speech enhancement. 

In contrast to current techniques, we operate at the waveform level, training the model end-to-end, and incorporate 28 speakers and 40 different noise conditions into the same model, such that model parameters are shared across them. 

We evaluate the proposed model using an independent, unseen test set with two speakers and 20 alternative noise conditions. 

The enhanced samples confirm the viability of the proposed model, and both objective and subjective evaluations confirm the effectiveness of it. 

With that, we open the exploration of generative architectures for speech enhancement, which may progressively incorporate further speech-centric design choices to improve their performance.
```

139. Donahue C, McAuley J, Puckette M. Adversarial audio synthesis. In: Proc. of the 7th Int’l Conf. on Learning Representations (ICLR). 2019.

Link : https://arxiv.org/abs/1802.04208

Note : Chris 等人提出了无监督音频合成模型,能够从小规模语音库中学习生成可理解的词汇

```
Audio signals are sampled at high temporal resolutions, and learning to synthesize audio requires capturing structure across a range of timescales. 

Generative adversarial networks (GANs) have seen wide success at generating images that are both locally and globally coherent, but they have seen little application to audio generation. 

In this paper we introduce WaveGAN, a first attempt at applying GANs to unsupervised synthesis of raw-waveform audio. 

WaveGAN is capable of synthesizing one second slices of audio waveforms with global coherence, suitable for sound effect generation. 

Our experiments demonstrate that, without labels, WaveGAN learns to produce intelligible words when trained on a small-vocabulary speech dataset, and can also synthesize audio from other domains such as drums, bird vocalizations, and piano. 

We compare WaveGAN to a method which applies GANs designed for image generation on image-like audio feature representations, finding both approaches to be promising.
```

140. Li XR, Yu K. A Deepfakes detection technique based on two-stream network. Journal of Cyber Security, 2020,5(2):84−91 (in Chinese with English abstract).

Link : https://jcs.iie.ac.cn/xxaqxben/ch/reader/view_abstract.aspx?file_no=20200208

Note : 深度伪造生成技术开源工具与商业软件做了部分总结

```
With the rapid development of deep learning technology, Deep forgery techniques, such as Deepfakes, are beginning to fill every corner of the Internet. 

By utilizing the generative adversarial networks and auto-encoder technology, the Deepfakes replace faces and tamper with facial expressions easily. 

The Deepfakes can produce fake pornography, spread rumors, spread fake news, and even influence political elections, leading to disastrous social consequences. 

However, the detection technology for this kind of fake videos is still far behind the generation technology, and the existing works have some limitations. 

This paper first summarizes the existing generation and detection works, and analyzes the defects of the existing works, then we propose the two-stream network detection framework based on the EfficientNet. 

By testing on a large open source dataset, FaceForensics++, our detection method was able to detect fake videos with an average accuracy of over 99%, and improve the ability of the model to resist compression to a certain extent.

```

141. FakeApp. 2019. https://www.deepfakescn.com

Link : https://www.deepfakescn.com

Note : 商业化工具, 深度伪造生成技术


142. Faceapp. 2019. https://www.faceapp.com/

Link : https://www.faceapp.com/

Note : 商业化工具, 深度伪造生成技术


143. DeepFaceLab. 2019. https://github.com/iperov/DeepFaceLab

Link : https://github.com/iperov/DeepFaceLab

Note : DeepfaceLab 对 Faceswap 项目的模型进行扩充,对人脸模型进行扩充


144. Dfaker. 2019. https://github.com/dfaker/df

Link : https://github.com/dfaker/df

Note : DFaker, 使用 DSSIM loss 函数


145. DeepFake-tf. 2019. https://github.com/StromWine/DeepFake-tf

Link : https://github.com/StromWine/DeepFake-tf

Note : DeepFake-tf,同 Dfakeer 项目,使用 tensorflow 实现


146. Faceswap-Deepfake-Pytorch. 2019. https://github.com/Oldpan/Faceswap-Deepfake-Pytorch

Link :  https://github.com/Oldpan/Faceswap-Deepfake-Pytorch

Note : Faceswap-DeepfakePytorch,原理同 Faceswap 项目,使用 Pytorch 实现


147. Deep-voice-conversion. 2020. https://github.com/andabi/deep-voice-conversion

Link : https://github.com/andabi/deep-voice-conversion

Note : Deep-voicevconversion, 只需要目标说话者的音波素材, 即可转换成特定目标人物的声音



148. MelNet. 2020. https://sjvasquez.github.io/blog/melnet/

Link : https://sjvasquez.github.io/blog/melnet/

Note : MelNet 基于频谱图的端到端语音生成


149. Matern F, Riess C, Stamminger M. Exploiting visual artifacts to expose Deepfakes and face manipulations. In: Proc. of the IEEE Winter Applications of Computer Vision Workshops (WACVW). IEEE, 2019. 83−92.

Link : https://ieeexplore.ieee.org/document/8638330

Note : 深度伪造开源数据集, UADFV, FakeAPP, 早期视频数据,量小

```
High quality face editing in videos is a growing concern and spreads distrust in video content. 

However, upon closer examination, many face editing algorithms exhibit artifacts that resemble classical computer vision issues that stem from face tracking and editing.

As a consequence, we wonder how difficult it is to expose artificial faces from current generators? 

To this end, we review current facial editing methods and several characteristic artifacts from their processing pipelines. 

We also show that relatively simple visual artifacts can be already quite effective in exposing such manipulations, including Deepfakes and Face2Face. 

Since the methods are based on visual features, they are easily explicable also to non-technical experts. 

The methods are easy to implement and offer capabilities for rapid adjustment to new manipulation types with little data available. 

Despite their simplicity, the methods are able to achieve AUC values of up to 0.866.
```


