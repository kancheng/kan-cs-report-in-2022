# DMSASD - 数字媒体软件与系统开发 - Digital Media Software And System Development

> 2101212850 干皓丞

PKU 2022 個人實驗報告作業

## Details

M2TR: Multi-modal Multi-scale Transformers for Deepfake Detection

Wang, J., Wu, Z., Chen, J., & Jiang, Y. G. (2021). M2tr: Multi-modal multi-scale transformers for deepfake detection. arXiv preprint arXiv:2104.09770.

https://arxiv.org/abs/2104.09770

```
The widespread dissemination of forged images generated by Deepfake techniques has posed a serious threat to the trustworthiness of digital information. 

This demands effective approaches that can detect perceptually convincing Deepfakes generated by advanced manipulation techniques. 

Most existing approaches combat Deepfakes with deep neural networks by mapping the input image to a binary prediction without capturing the consistency among different pixels. 

In this paper, we aim to capture the subtle manipulation artifacts at different scales for Deepfake detection. 

We achieve this with transformer models, which have recently demonstrated superior performance in modeling dependencies between pixels for a variety of recognition tasks in computer vision. 

In particular, we introduce a Multi-modal Multi-scale TRansformer (M2TR), which uses a multi-scale transformer that operates on patches of different sizes to detect the local inconsistency at different spatial levels. 

To improve the detection results and enhance the robustness of our method to image compression, M2TR also takes frequency information, which is further combined with RGB features using a cross modality fusion module. 

Developing and evaluating Deepfake detection methods requires large-scale datasets. However, we observe that samples in existing benchmarks contain severe artifacts and lack diversity. 

This motivates us to introduce a high-quality Deepfake dataset, SR-DF, which consists of 4,000 DeepFake videos generated by state-of-the-art face swapping and facial reenactment methods. 

On three Deepfake datasets, we conduct extensive experiments to verify the effectiveness of the proposed method, which outperforms state-of-the-art Deepfake detection methods.
```

Deepfake 技術所產生的偽造圖像廣泛傳播對數位資訊的可信度構成了嚴重威脅，這需要有效的方法來檢測由先進技術所生成具有感知力的 Deepfake 成果。大多數現有方法通過將輸入圖像對應到二進制預測而不捕獲不同像素之間的一致性來使用深度神經網絡來對抗 Deepfakes 技術。在該研究中，研究者旨在為 Deepfake 檢測捕獲不同尺度的細微操作偽影，並通過轉換器模型實現了這一點，該模型最近在為計算機視覺中的各種識別任務建模像素之間的依賴關係方面表現出卓越的性能。同時研究者介紹了一種多模態多尺度變換器（M2TR），它使用多尺度變換器對不同大小的補丁進行操作，以檢測不同空間級別的局部不一致性，為了改善檢測結果並增強我們方法對圖像壓縮的魯棒性，M2TR 還獲取頻率信息，並使用交叉模態融合模塊將其與 RGB 特徵進一步結合。開發和評估 Deepfake 檢測方法需要大規模的數據集。此研究觀察到現有基準中的樣本包含嚴重的偽影並且缺乏多樣性，這促使此研究引入了一個高品質的 Deepfake 資料集 SR-DF，它由 4,000 個由最先進的面部交換和面部重演方法去生成的 DeepFake 組成影像，最後在三個 Deepfake 資料集上，研究者進行了廣泛的實驗來驗證所提出方法的有效性，該方法優於最先進的 Deepfake 檢測方法。

Bibliography

```
@article{wang2021m2tr,
  title={M2tr: Multi-modal multi-scale transformers for deepfake detection},
  author={Wang, Junke and Wu, Zuxuan and Chen, Jingjing and Jiang, Yu-Gang},
  journal={arXiv preprint arXiv:2104.09770},
  year={2021}
}
```